{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOD5kVWPNvZD+5KvLgN2XTY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9640e2060da3454aa1d5d6d126a9413a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_942c8d9273bd42cca4b765a8448091b9",
              "IPY_MODEL_47d7a8008ec64b38808a4031a1997b65",
              "IPY_MODEL_71a256b810d24e4ea22f1e9f268856db"
            ],
            "layout": "IPY_MODEL_f24cec9d776345c7a9a9061c7e736f9f"
          }
        },
        "942c8d9273bd42cca4b765a8448091b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfab4a63926a43bc86f066857b521f42",
            "placeholder": "​",
            "style": "IPY_MODEL_b8136f0a0c194813a30b30baa225900d",
            "value": "Map: 100%"
          }
        },
        "47d7a8008ec64b38808a4031a1997b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_102dcd473fb14d1195efa2ff218fa839",
            "max": 2425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc51ab6c0aa44318a88f6b497ae9f41f",
            "value": 2425
          }
        },
        "71a256b810d24e4ea22f1e9f268856db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e6998491e244a2fb988992d878e54bc",
            "placeholder": "​",
            "style": "IPY_MODEL_be3a45bb143b44f78378d2ef3759b815",
            "value": " 2425/2425 [00:05&lt;00:00, 441.21 examples/s]"
          }
        },
        "f24cec9d776345c7a9a9061c7e736f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfab4a63926a43bc86f066857b521f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8136f0a0c194813a30b30baa225900d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "102dcd473fb14d1195efa2ff218fa839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc51ab6c0aa44318a88f6b497ae9f41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e6998491e244a2fb988992d878e54bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be3a45bb143b44f78378d2ef3759b815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bd44ebb82d248d1af07892c361b4b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_025d0a7d2f7d41c7865bdad54ec3c59b",
              "IPY_MODEL_8cff29837ebf410ea861cf0d6c8f3780",
              "IPY_MODEL_85b2b2feed554d66b6b04d930d2bee1a"
            ],
            "layout": "IPY_MODEL_bf9dd5fb8cc8452bb8ca27a051eb10ae"
          }
        },
        "025d0a7d2f7d41c7865bdad54ec3c59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8868b2f9a4054adeb6a54d22f565d007",
            "placeholder": "​",
            "style": "IPY_MODEL_1f8df0f6bcbb4c69a6f7867e91d10d8a",
            "value": "Map: 100%"
          }
        },
        "8cff29837ebf410ea861cf0d6c8f3780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d6895ac7ac4804a876e9072a741841",
            "max": 2425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a936e85ea963412eaabd5d42187081ba",
            "value": 2425
          }
        },
        "85b2b2feed554d66b6b04d930d2bee1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48c6b309bd4d44d69a2819957371d9ad",
            "placeholder": "​",
            "style": "IPY_MODEL_0cc5936166ed4eaf9d392f6658580c3e",
            "value": " 2425/2425 [00:05&lt;00:00, 452.50 examples/s]"
          }
        },
        "bf9dd5fb8cc8452bb8ca27a051eb10ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8868b2f9a4054adeb6a54d22f565d007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8df0f6bcbb4c69a6f7867e91d10d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3d6895ac7ac4804a876e9072a741841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a936e85ea963412eaabd5d42187081ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48c6b309bd4d44d69a2819957371d9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cc5936166ed4eaf9d392f6658580c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c03f197452844740893645316b4a5c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0726f9417ff04970a32fae1c0d6b8a37",
              "IPY_MODEL_e32d48245d00400a8a89c2a3aa761f4b",
              "IPY_MODEL_758b268fa7004c0f88f856636d03ac8d"
            ],
            "layout": "IPY_MODEL_d2ab4cd8cdd340829a4fb960f2a0599c"
          }
        },
        "0726f9417ff04970a32fae1c0d6b8a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27a99990a6e34653b841c7c792c0648e",
            "placeholder": "​",
            "style": "IPY_MODEL_0a54481688af441d911ba69823d9cbc3",
            "value": "Map: 100%"
          }
        },
        "e32d48245d00400a8a89c2a3aa761f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_507cf50f044c4290a053d8b1d1ea823e",
            "max": 1681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2aa3bc704cc3493db37f84502d72efd6",
            "value": 1681
          }
        },
        "758b268fa7004c0f88f856636d03ac8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb86e46d37454d3f9d18eb6eed96bc24",
            "placeholder": "​",
            "style": "IPY_MODEL_da0134ef40114f9a9c1c7da334eb4dd8",
            "value": " 1681/1681 [00:03&lt;00:00, 436.56 examples/s]"
          }
        },
        "d2ab4cd8cdd340829a4fb960f2a0599c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27a99990a6e34653b841c7c792c0648e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a54481688af441d911ba69823d9cbc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "507cf50f044c4290a053d8b1d1ea823e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aa3bc704cc3493db37f84502d72efd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb86e46d37454d3f9d18eb6eed96bc24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da0134ef40114f9a9c1c7da334eb4dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f02a77ca3f474c6396a21281aa6d7a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_822cfd80efbd43e19462bbaa860415e6",
              "IPY_MODEL_bd0bd757fe1f4df286ec9fdca2bcd300",
              "IPY_MODEL_5495c37bd4bb4b3db207cec64bac976c"
            ],
            "layout": "IPY_MODEL_2fa7073862544a94ad5cdfa1bd834588"
          }
        },
        "822cfd80efbd43e19462bbaa860415e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca2477e11e42450cb66a36c42f996c3f",
            "placeholder": "​",
            "style": "IPY_MODEL_e710fc2b0504465eb0a873e98062de36",
            "value": "Map: 100%"
          }
        },
        "bd0bd757fe1f4df286ec9fdca2bcd300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_662659310b424c48bd1e30f3a5612d82",
            "max": 249,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33b992f8f71d46ba8d8ca7bcaa152ebc",
            "value": 249
          }
        },
        "5495c37bd4bb4b3db207cec64bac976c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7643359b004b1792f80399cf1641eb",
            "placeholder": "​",
            "style": "IPY_MODEL_4323720d62fd446e9bd36ed9cab16700",
            "value": " 249/249 [00:00&lt;00:00, 407.93 examples/s]"
          }
        },
        "2fa7073862544a94ad5cdfa1bd834588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca2477e11e42450cb66a36c42f996c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e710fc2b0504465eb0a873e98062de36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "662659310b424c48bd1e30f3a5612d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b992f8f71d46ba8d8ca7bcaa152ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a7643359b004b1792f80399cf1641eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4323720d62fd446e9bd36ed9cab16700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "437b41c9c5474661b2e3a6a77a53b423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b24a2164b3bd486692c111cb50c3cb8c",
              "IPY_MODEL_86f804f954894b0a800a115459b4575a",
              "IPY_MODEL_eda5fae782c64c4fb4db441baaaf77bd"
            ],
            "layout": "IPY_MODEL_d647088129124736b28e991765a41d4a"
          }
        },
        "b24a2164b3bd486692c111cb50c3cb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ca8256b94e74654a1498595f98144d3",
            "placeholder": "​",
            "style": "IPY_MODEL_71ddeaa0f9f2438b83024542f50e826c",
            "value": "Map: 100%"
          }
        },
        "86f804f954894b0a800a115459b4575a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0749dedfafd415cb11918a0feb2e1a7",
            "max": 495,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_031cfe2307f948b5ad91eb77917e2294",
            "value": 495
          }
        },
        "eda5fae782c64c4fb4db441baaaf77bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c315eb6b1d4f9590124f213681ecac",
            "placeholder": "​",
            "style": "IPY_MODEL_9f38febe619045f1982bc3dc709db048",
            "value": " 495/495 [00:01&lt;00:00, 385.39 examples/s]"
          }
        },
        "d647088129124736b28e991765a41d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ca8256b94e74654a1498595f98144d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71ddeaa0f9f2438b83024542f50e826c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0749dedfafd415cb11918a0feb2e1a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "031cfe2307f948b5ad91eb77917e2294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49c315eb6b1d4f9590124f213681ecac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f38febe619045f1982bc3dc709db048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7825c0c66d82438280dbcd7d3299ef8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd3bc6fb59134e2ebc4eec17add8ed95",
              "IPY_MODEL_4fe6be5b220d41d490bca62087652895",
              "IPY_MODEL_51ecd5c57db74795a0f431dfd97ba9d2"
            ],
            "layout": "IPY_MODEL_32ef0cc106014bc3b332841c7a8fd6d3"
          }
        },
        "fd3bc6fb59134e2ebc4eec17add8ed95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc3a18cbc1c54fa59c3251ba021a8225",
            "placeholder": "​",
            "style": "IPY_MODEL_627b580d42144dbc82fb0fe006cce69d",
            "value": "Map: 100%"
          }
        },
        "4fe6be5b220d41d490bca62087652895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_367ebdffdf1043c5a53ad40adb2a2da3",
            "max": 121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c32cd45f338345189b641effe097a526",
            "value": 121
          }
        },
        "51ecd5c57db74795a0f431dfd97ba9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a8d06a05aa485a94c9ac3eafc5188c",
            "placeholder": "​",
            "style": "IPY_MODEL_009330a52b8a427c93c1ecb5fbcaf42e",
            "value": " 121/121 [00:00&lt;00:00, 340.96 examples/s]"
          }
        },
        "32ef0cc106014bc3b332841c7a8fd6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc3a18cbc1c54fa59c3251ba021a8225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627b580d42144dbc82fb0fe006cce69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "367ebdffdf1043c5a53ad40adb2a2da3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32cd45f338345189b641effe097a526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46a8d06a05aa485a94c9ac3eafc5188c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009330a52b8a427c93c1ecb5fbcaf42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5053345ca1ce4f249f204187edd6c3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b11f01b8af9d4f81b72c0fe48f873677",
              "IPY_MODEL_2b353e37c6f8473ca7f15eddab73dbb0",
              "IPY_MODEL_8dffbf5167dc447baa48bec3493486a1"
            ],
            "layout": "IPY_MODEL_af078c18a50e4b72a1c03438a0960279"
          }
        },
        "b11f01b8af9d4f81b72c0fe48f873677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94b04377d1074b9d8b805095ee9e2210",
            "placeholder": "​",
            "style": "IPY_MODEL_81091e63d1514fae96781d0268740bac",
            "value": "Map: 100%"
          }
        },
        "2b353e37c6f8473ca7f15eddab73dbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ab2ac81fd2a478ba2f3a657473a469c",
            "max": 2425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d5291091ba94c319a536e194805d057",
            "value": 2425
          }
        },
        "8dffbf5167dc447baa48bec3493486a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9373cdc0dcbb411c971c5f4d56c45208",
            "placeholder": "​",
            "style": "IPY_MODEL_279d8217bc6d4b97bf45791645ffd54c",
            "value": " 2425/2425 [00:06&lt;00:00, 387.78 examples/s]"
          }
        },
        "af078c18a50e4b72a1c03438a0960279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94b04377d1074b9d8b805095ee9e2210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81091e63d1514fae96781d0268740bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ab2ac81fd2a478ba2f3a657473a469c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d5291091ba94c319a536e194805d057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9373cdc0dcbb411c971c5f4d56c45208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "279d8217bc6d4b97bf45791645ffd54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eec8f999763d4bd19f4c185c4a2c2622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb230a3c68054baf804c15207ffd3a6d",
              "IPY_MODEL_9cf9c125a156471f9ad5f08754bea1ba",
              "IPY_MODEL_a7b33dfa05254932b71c76b2a9ff16f1"
            ],
            "layout": "IPY_MODEL_bac2ea678c1b4357b4d718750a22f4ab"
          }
        },
        "bb230a3c68054baf804c15207ffd3a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd885dff3de8498081e9b3cc5efb202d",
            "placeholder": "​",
            "style": "IPY_MODEL_afb318cbf3aa481db17db8d03fb87d30",
            "value": "Downloading builder script: "
          }
        },
        "9cf9c125a156471f9ad5f08754bea1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bb7cf12b1d849198350447953a4a19a",
            "max": 2169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_521f2798319e49559a1a8d786efda1f5",
            "value": 2169
          }
        },
        "a7b33dfa05254932b71c76b2a9ff16f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a479f60f3c447e4b34628676ab300b1",
            "placeholder": "​",
            "style": "IPY_MODEL_ed3bc433f2bb442abc6cff9227382342",
            "value": " 5.65k/? [00:00&lt;00:00, 481kB/s]"
          }
        },
        "bac2ea678c1b4357b4d718750a22f4ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd885dff3de8498081e9b3cc5efb202d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afb318cbf3aa481db17db8d03fb87d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bb7cf12b1d849198350447953a4a19a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "521f2798319e49559a1a8d786efda1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a479f60f3c447e4b34628676ab300b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed3bc433f2bb442abc6cff9227382342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelJucker/MACHINE_LEARNING_JUCKESAM/blob/master/custom_finnews_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparation:**\n",
        "\n",
        "Install the following libraries"
      ],
      "metadata": {
        "id": "tAuZ--lmoo04"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCMMfa_CnrRU",
        "outputId": "67226db4-8534-4503-d5a9-b9122a4a4995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests (from transformers)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.19.2 dill-0.3.8 multiprocess-0.70.16 requests-2.32.3 xxhash-3.4.1\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets\n",
        "!pip install transformers[torch] accelerate -U"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6MYgieU_o5dp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necessary imports // if not acess to drive just comment it out"
      ],
      "metadata": {
        "id": "Bio0yqP4uPky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import transformers\n",
        "import accelerate\n",
        "import torch\n",
        "import shutil\n",
        "import os\n",
        "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, GenerationConfig\n",
        "from datasets import load_dataset\n",
        "from google.colab import drive\n",
        "\n",
        "import random  # Add this line to import the random module\n",
        "import pandas as pd  # Ensure pandas is imported for DataFrame usage\n",
        "from datasets import Dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kuwt10w5o0D3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading / model and tokenizer"
      ],
      "metadata": {
        "id": "h5Z7edHOyPfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the Save Path\n",
        "drive_save_path = '/content/drive/My Drive/fine_tuned_model'\n",
        "\n",
        "# Load the pretrained model and tokenizer\n",
        "model_name = \"google/pegasus-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "base_model = model_name.split('/')[1]  # Extract the base model name for later use\n",
        "\n",
        "# Define the directory to save the model and tokenizer\n",
        "save_directory = \"./pretrained_pegasus_large\"\n",
        "\n",
        "# Save the pretrained model and tokenizer to the directory\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "# Print all files in the save directory\n",
        "# print(\"Files in the save directory:\")\n",
        "# for root, dirs, files in os.walk(save_directory):\n",
        "#     for filename in files:\n",
        "#         print(os.path.join(root, filename))\n",
        "\n",
        "# Assuming you have already fine-tuned the model and tokenizer\n",
        "model.save_pretrained('./results')\n",
        "tokenizer.save_pretrained('./results')\n",
        "\n",
        "# Optionally, save the generation configuration if used\n",
        "gen_config = GenerationConfig(\n",
        "    max_length=142,\n",
        "    min_length=56,\n",
        "    early_stopping=True,\n",
        "    num_beams=4,\n",
        "    length_penalty=2.0,\n",
        "    no_repeat_ngram_size=3,\n",
        "    forced_bos_token_id=0,\n",
        "    forced_eos_token_id=2\n",
        ")\n",
        "gen_config.save_pretrained('./results')\n",
        "\n",
        "# List of files to keep (fine-tuned files)\n",
        "files_to_keep = [\n",
        "    \"config.json\",\n",
        "    \"generation_config.json\",\n",
        "    \"model.safetensors\",  # or 'pytorch_model.bin'\n",
        "    \"special_tokens_map.json\",\n",
        "    \"spiece.model\",\n",
        "    \"tokenizer.json\",\n",
        "    \"tokenizer_config.json\"\n",
        "]\n",
        "\n",
        "# Print all files in the fine-tuned directory to ensure they are saved\n",
        "print(\"Files in the fine-tuned directory:\")\n",
        "for root, dirs, files in os.walk('./results'):\n",
        "    for filename in files:\n",
        "        print(os.path.join(root, filename))\n",
        "\n",
        "# Step 4: Copy Only Fine-Tuned Files to Google Drive\n",
        "# If the directory exists, delete it first\n",
        "if os.path.exists(drive_save_path):\n",
        "    shutil.rmtree(drive_save_path)\n",
        "\n",
        "# Create the directory in Google Drive\n",
        "os.makedirs(drive_save_path)\n",
        "\n",
        "# Copy only the necessary files to Google Drive\n",
        "for file_name in files_to_keep:\n",
        "    src_path = os.path.join('./results', file_name)\n",
        "    dest_path = os.path.join(drive_save_path, file_name)\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.copy(src_path, dest_path)\n",
        "        print(f\"Copied {src_path} to {dest_path}\")\n",
        "    else:\n",
        "        print(f\"{src_path} does not exist\")\n",
        "\n",
        "# Print all files in the Google Drive save directory to ensure they are saved\n",
        "print(\"Files in the Google Drive save directory:\")\n",
        "for root, dirs, files in os.walk(drive_save_path):\n",
        "    for filename in files:\n",
        "        print(os.path.join(root, filename))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7d0Bpnjo0Bh",
        "outputId": "b6e2d870-90a5-4a19-fc31-191f4fb23fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 256, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 256, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the fine-tuned directory:\n",
            "./results/config.json\n",
            "./results/model.safetensors\n",
            "./results/tokenizer.json\n",
            "./results/spiece.model\n",
            "./results/special_tokens_map.json\n",
            "./results/tokenizer_config.json\n",
            "./results/generation_config.json\n",
            "./results/checkpoint-500/config.json\n",
            "./results/checkpoint-500/model.safetensors\n",
            "./results/checkpoint-500/trainer_state.json\n",
            "./results/checkpoint-500/optimizer.pt\n",
            "./results/checkpoint-500/training_args.bin\n",
            "./results/checkpoint-500/scheduler.pt\n",
            "./results/checkpoint-500/generation_config.json\n",
            "./results/checkpoint-500/rng_state.pth\n",
            "./results/checkpoint-1000/config.json\n",
            "./results/checkpoint-1000/model.safetensors\n",
            "./results/checkpoint-1000/trainer_state.json\n",
            "./results/checkpoint-1000/optimizer.pt\n",
            "./results/checkpoint-1000/training_args.bin\n",
            "./results/checkpoint-1000/scheduler.pt\n",
            "./results/checkpoint-1000/generation_config.json\n",
            "./results/checkpoint-1000/rng_state.pth\n",
            "./results/checkpoint-1500/config.json\n",
            "./results/checkpoint-1500/model.safetensors\n",
            "./results/checkpoint-1500/trainer_state.json\n",
            "./results/checkpoint-1500/optimizer.pt\n",
            "./results/checkpoint-1500/training_args.bin\n",
            "./results/checkpoint-1500/scheduler.pt\n",
            "./results/checkpoint-1500/generation_config.json\n",
            "./results/checkpoint-1500/rng_state.pth\n",
            "./results/runs/Jun08_18-31-55_834c0497bd01/events.out.tfevents.1717872458.834c0497bd01.1116.1\n",
            "./results/runs/Jun08_18-31-55_834c0497bd01/events.out.tfevents.1717871517.834c0497bd01.1116.0\n",
            "Copied ./results/config.json to /content/drive/My Drive/fine_tuned_model/config.json\n",
            "Copied ./results/generation_config.json to /content/drive/My Drive/fine_tuned_model/generation_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "take a look at this: https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model"
      ],
      "metadata": {
        "id": "isepRmnpvfFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataload / data preproc etc not in collab"
      ],
      "metadata": {
        "id": "nH8A1ApIyWDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the dataset name\n",
        "dataset_name = \"this can vary\"\n"
      ],
      "metadata": {
        "id": "CmMu3WOAyaMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_name = \"cnn_dailymail\"\n",
        "# dataset_version = \"3.0.0\"\n"
      ],
      "metadata": {
        "id": "Ndqh82Hgymi4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load temporary dataset, currently temp future final temp down."
      ],
      "metadata": {
        "id": "UQc5NX1oqdpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nDHkfiXo30in"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import random\n",
        "\n",
        "# Load the JSON files\n",
        "train_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_train.jsonl'\n",
        "val_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_val.jsonl'\n",
        "test_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_test.jsonl'\n",
        "\n",
        "# Read the JSONL files\n",
        "train_data = []\n",
        "with open(train_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        train_data.append(json.loads(line))\n",
        "\n",
        "val_data = []\n",
        "with open(val_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        val_data.append(json.loads(line))\n",
        "\n",
        "test_data = []\n",
        "with open(test_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        test_data.append(json.loads(line))\n",
        "train_df = pd.DataFrame(train_data)  # Added this line to define train_df\n",
        "val_df = pd.DataFrame(val_data)      # Added this line to define val_df\n",
        "test_df = pd.DataFrame(test_data)    # Added this line to define test_df\n",
        "\n",
        "# Convert to DataFrames for better handling\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "validation_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "\n",
        "# Combine the datasets for preprocessing and fine-tuning\n",
        "combined_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "# Retrieve a random sample\n",
        "random_index = random.randint(0, len(combined_df) - 1)\n",
        "initial_sample = combined_df.iloc[random_index]\n",
        "print(\"Random sample from the initial dataset (before processing):\")\n",
        "print(initial_sample)\n",
        "\n",
        "# Convert DataFrame to Dataset\n",
        "dataset = Dataset.from_pandas(combined_df)\n",
        "\n",
        "# Load the tokenizer\n",
        "model_name = \"google/pegasus-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Define a preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    inputs = [doc for doc in examples[\"input\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Apply the preprocessing function to the dataset\n",
        "processed_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Retrieve the processed sample\n",
        "processed_sample = processed_dataset[random_index]\n",
        "print(\"\\nRandom sample from the processed dataset (after processing):\")\n",
        "print(processed_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "9640e2060da3454aa1d5d6d126a9413a",
            "942c8d9273bd42cca4b765a8448091b9",
            "47d7a8008ec64b38808a4031a1997b65",
            "71a256b810d24e4ea22f1e9f268856db",
            "f24cec9d776345c7a9a9061c7e736f9f",
            "dfab4a63926a43bc86f066857b521f42",
            "b8136f0a0c194813a30b30baa225900d",
            "102dcd473fb14d1195efa2ff218fa839",
            "fc51ab6c0aa44318a88f6b497ae9f41f",
            "9e6998491e244a2fb988992d878e54bc",
            "be3a45bb143b44f78378d2ef3759b815"
          ]
        },
        "id": "kzkwBa5cykrs",
        "outputId": "90555a33-c37f-49e0-c584-fa10f7c8a6b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sample from the initial dataset (before processing):\n",
            "ticker                                                    FL\n",
            "quarter                                                   q1\n",
            "year                                                    2021\n",
            "input      On a per share basis, first quarter earnings w...\n",
            "summary    foot locker q1 non-gaap earnings per share $1....\n",
            "Name: 2100, dtype: object\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2425 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9640e2060da3454aa1d5d6d126a9413a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random sample from the processed dataset (after processing):\n",
            "{'ticker': 'FL', 'quarter': 'q1', 'year': '2021', 'input': \"On a per share basis, first quarter earnings were $1.93 compared to a loss per share of $1.06 last year and earnings per share of $1.52 for the first quarter of 2019.\\nThis year's quarter includes pre-tax charges of $2 million related to the impairment of one of the company's minority investments, and $2 million primarily related to severance costs in connection with the reorganization of certain support functions.\\nExcluding these items, first quarter non-GAAP earnings were $1.96 per share, a significant reversal to the loss per share of $0.67 for the first quarter of last year and up 28.1% compared to earnings per share of $1.53 for the first quarter of 2019.\\nWe're excited to have him on board.\\nLast quarter, I talked about entering our fiscal 2021 momentum.\\nThat was certainly the case in our first quarter.\\nAnd the momentum gained strength as the quarter progressed, enabling us to deliver exceptional top line and bottom line results, even against the ongoing challenges of store closures in Europe and Canada and congestion at the U.S. ports, leading to abnormally lean inventory levels.\\nOn a sequential basis, comps dramatically accelerated through the quarter, led by our stores.\\nA mid-teens decline in February due mainly to launch calendar shifts and tax refund delays gave way to strong triple-digit gains in March and April as we lapped the onset of the COVID pandemic last year and the disruption caused by the shutdown of our store fleet.\\nBut our stores weren't the only highlight.\\nOur digital business also remained quite strong, up 43% on a comp basis and landing at a penetration rate of 25% of our total sales, which was higher than our expectations coming into the quarter.\\nPerhaps more impressively, even with the challenges I mentioned, our sales performance was not only strong relative to last year's unprecedented first quarter, but also versus Q1 2019, where we saw low single-digit growth versus a strong result that year.\\nAthleisure and fitness consumer trends continued to drive strong demand across genders and families of business.\\nAlthough our inventory levels were lower than we would have liked, the composition and quality of goods was fresh, and our consumers responded very well to our merchandise assortments.\\nThis resulted in higher inventory productivity and significantly less promotional activity, enabling us to deliver healthier margins and a truly impressive bottom-line performance.\\nFinally, we believe U.S. government stimulus and tax refunds provided incremental positives in the quarter.\\nThis stellar performance would not have been possible without all of the associates whose dedication to the success of our company and whose passion for creating incredible experiences for our customers drives our business every day.\\nI often say we have the best team in retail, and our performance in Q1 serves as a testament to the strength of our team.\\nAs we expected, COVID-related restrictions pressured our business in Europe throughout Q1, as the EMEA fleet was opened only 39% of possible operating days in the quarter.\\nBut omnichannel growth was positive, nonetheless.\\nAnd in pockets where lockdowns began to ease, such as the U.K., we saw pent-up demand drive growth at the store level as well, leaving us optimistic that the trend will continue as the region opens back up.\\nTo that end, we continue to break exciting new ground in Europe, including today's opening of our first high-profile store in Barcelona.\\nThe store features dedicated women's and kids' spaces, local artwork and curation and enhanced connectivity, including a digital interactive zone and BOPIS lockers.\\nAdditionally, we refreshed several stores across EMEA during Q1, with upgrades to fixtures, layouts and light touch improvements as we anticipate the broader reopening of the economy in EMEA.\\nLooking ahead, we continue to have strong product tailwinds, led by the culture of basketball and footwear, comfort trends in apparel and new and exciting strategic brands in our portfolio, which Andy will talk to in more detail.\\nWhile we continue to manage against the remaining port delays and gradual reopening's in Europe and Canada, these are transient issues, and we remain optimistic about our prospects as we move through the year.\\nAs it relates to the West Coast ports, there's some good news to share.\\nInventory flow and receipt velocity did improve as delays began to ease through the first quarter, and we expect further improvement in Q2, which should reflect positively on our inventory levels.\\nIn the meantime, we have been working with our vendor partners to utilize ultimate ports and expedited rail and truck services to accelerate the flow of goods.\\nNow let me provide an update on our strategic initiatives and technology milestones.\\nWe continue to see enrollment increase with over 20 million members now enrolled in the countries where the program is active.\\nWe also continue to refine the KPIs that will define success for FLX moving forward, including customer retention and satisfaction.\\nIn addition to growing membership in 2021, we will also focus on expanding into additional countries, driving engagement and incremental spend by connecting in more relevant ways with our customers and integrating FLX deeper into the customer experience at Foot Locker, Inc., adding value to programs like BOPIS and Launch Reservation.\\nNow for some highlights on our key technology initiatives.\\nFirst, we continued to build on our new payments platform, adding Adyen, Giropay, and Clearpay to our selection of payment options in Europe.\\nProviding increased convenience and flexibility for our consumer remains an imperative for us, and these new options will complement the successful rollout of Apple Pay and Google Pay last quarter.\\nSecond, as part of our digital commerce transformation, we deployed new websites in four additional European countries: the U.K., Netherlands, Germany and France, that build off the modernized platform we launched in North America last year.\\nThe new sites are easier to personalize to local markets, less costly to maintain and better leverage data analytics.\\nFinally, we expanded the SKUs we offer on Eastbay as part of the Nike dropship program we announced in February, and we're working toward getting additional banners up on the program in the coming months.\\nHaving the right product at the right time is fundamental to our business.\\nThis program is one step toward providing more flexibility to meet customer demand.\\nNow I'd like to discuss an important update on our organizational evolution.\\nWe've talked a lot about how the accelerated shift to digital throughout pandemic pushed us to more quickly adapt to our consumers' changing preferences and to create stronger connections with them.\\nIt's also led us to proactively accelerate our initiatives to optimize our real estate portfolio in our best-performing banners and across the most valuable locations to competitively position our store fleet for the future.\\nThe decision to shutter Runners Point in Europe during 2020 is an example of this ongoing effort, as was the decision in the U.S. to more closely align Champs Sports and Eastbay.\\nWith that in mind, during the second quarter, we have made the strategic decision to wind down our Footaction banner over the next two years and focus our resources on our iconic concepts: Foot Locker, Kids Foot Locker, Champs Sports and Eastbay.\\nWe are currently in the process of assessing the Footaction fleet to determine the best decision for each location.\\nFirst, as we've discussed on prior calls, the flexibility we have with respect to our portfolio management will allow us to take advantage of a number of lease expirations over the next two years.\\nSecond, we plan to convert approximately one-third of the top-performing Footaction locations into new Foot Locker stores, establishing a bolder women's and kids presence as well as new Champs Sports and Kids Foot Locker stores.\\nWe are excited about the opportunities to expand our women's and kids presence within our Foot Locker and Champs Sports banners.\\nBut a decision like this is never easy.\\nThrough their contributions, we've gained valuable learnings and consumer insights.\\nAs we look ahead, we see this as an opportunity to strengthen our global portfolio of brands, increase our value to our shareholders and vendor partners and ultimately position Foot Locker, Inc. to better serve our consumers in a post-COVID marketplace.\\nAs part of our broader brick-and-mortar strategy, we will also continue to flex our powerful and expansive real estate portfolio to our advantage to accelerate our pivot off-mall, while continuing to invest in our community and Power Store assets.\\nWe also intend to grow the Champs Sports homefield concept, with extended assortment for men's, women's and kids that will expand to include lifestyle and performance categories.\\nIt truly speaks to the power of this category and our consumers' appetite for cool, premium product.\\nFor over a year now, we have been tested by the COVID pandemic and have prevailed as a leader in our industry.\\nMost importantly, COVID has taught us to innovate, to move faster and to go above and beyond for our consumers as we strive to inspire and empower youth culture.\\nMany parts of the world are still dealing with lockdowns due to emerging COVID variants and the uneven vaccine distribution.\\nWe continue to feel that impact on our business in Europe and Canada, where roughly 230 stores are temporarily closed.\\nThat said, there's a lot to be excited about right now in our business and industry.\\nTrends and momentum are strong.\\nOur strategic direction and focus have never been sharper.\\nOur financial position is in excellent shape and our bench of talent is deep.\\nI'm confident in our team's ability to take advantage of the many opportunities we see as the year progresses and the world continues to recover.\\nWith that, let me pass it over to Andy.\\nI'm looking forward to the partnership ahead.\\nThroughout the quarter, we remain focused on our strategies to strengthen our competitive advantages, while reinforcing our existing relationships and bringing new consumers into our business.\\nWe did that by building on three key areas of strength: Our product leadership and diversity; continuing to create a pipeline of new products, new brands, new categories and new ideas to excite our consumers; our omni experiences, utilizing our global scale and investments to enhance and further connect the digital and physical journey for our consumers; and our commitments to our communities, being of the community and in the community, and personalizing our relationships to make a meaningful impact on our consumers' lives.\\nAll of that was evident in the first quarter as we delivered new products, new content and new experiences to delight our consumers.\\nIn total, all our families of business were strong.\\nOur footwear business increased over 70%, while our apparel and accessory businesses were both up triple digits.\\nBoth families of business also increased as compared to 2019.\\nThe strength in footwear was broad-based with gains across all regions, led by North America and Asia Pacific.\\nSimilarly, we saw strong double-digit increases across men's, women's and kids' footwear, with our women's business driving the largest gain.\\nBy category, men's basketball continued to see healthy momentum, delivering a high double-digit increase led by the Jordan brand, key Nike icons and some compelling new initiatives by Puma and Reebok.\\nAdditionally, we brought new consumers into the business with an increased focus on our seasonal category.\\nThis helped to drive a triple-digit increase with gains in UGG, BIRKENSTOCK and new brand introductions, including Crocs.\\nMeanwhile, men's running increased strong double digits, led by the key franchises of Max Air, Adidas Nomad, Puma RS-X and strong momentum in our partnership with New Balance.\\nIt was also a strong quarter for our apparel business, which was up triple digits compared to the first quarter of last year and up double digits versus the first quarter of 2019.\\nMen's and kids led the way up triple digits, while women's increased strong double digits.\\nThe casualization of society remained the catalyst for our business, and we saw all major categories increase, with shorts driving the largest gain with momentum across many brands, including our own.\\nAnd across all product areas, our customers continue to respond well to elevated storytelling, with our consumer concept offense delivering exciting exclusive programs.\\nThese included, City to the World from Nike, and All Day I Dream About Sneakers with Adidas, which both feature unique versions of their respective iconic silhouettes.\\nWe also partnered with We Need Leaders and New Balance to pay homage to the leaders of the street running movement, and we created some fun with our Sesame Street and Champion collaboration.\\nLooking ahead, there's a lot coming to market to keep our consumers engaged.\\nThe culture of basketball remains strong with new launches from Adidas, Puma and New Balance bringing further dimension to the category.\\nWe are continuing our seasonal expansion with UGG, Crocs, Converse and Vans, and we have a very strong pipeline of ideas and inventory in apparel to maximize the ongoing momentum in the category.\\nAnd we will continue to enhance our storytelling in Q2 through our celebration of the 25th anniversary of the Griffey 1 with our Nike concept and our second installment of All Day I Dream About Sneakers with Adidas.\\nWe also have exciting collaborations in the pipeline with the likes of Kids of Immigrants and Vans, Louis de Guzman and New Balance, and Puma and White Castle, to name a few.\\nBeyond product, I also remain enthusiastic about our community initiatives and how we continue to lead with purpose and extend our community stores across the globe and expand our local geo teams to ensure that we are more deeply rooted in the neighborhoods we serve.\\nThat includes local experiences, local products and local give back.\\nAnd we continue to bring this to life with the openings of Foot Locker and Kids Foot Locker in Old Spanish Trail in Houston and Champs Sports in the Oakbrook Mall in Chicago.\\nWe also continue to fuel the future of our industry for the next generation of creators through our greenhouse incubator and our homegrown and lead initiatives.\\nOn the latter, in addition to our work to advance education and economic opportunities for the black communities we serve, we have also established partnerships with 45 new black-owned brands and creators to provide a platform to showcase their design collaborations this year.\\nNext to that, we also continue to invest in growing our membership and enhancing our consumer journey through the geographic rollout of FLX and adding millions of new members to our business in Q1, expanding our dropship initiative, elevating our mobile app experience, enhancing our buy online and pickup in-store journey, providing new payment options and much more, all to better serve our consumer.\\nSo a lot of work against our key strategic initiatives as we continue to push our consumer offense forward.\\nIt's a combination of product leadership and diversity, our enhanced omni capabilities and our focus on community and purpose that will keep us moving forward and strengthen our relationship with our consumers.\\nLet me now pass the call over to Andrew.\\nIt is my pleasure to join you today to discuss our first quarter results.\\nAs a consumer of this brand, Foot Locker always stood out to me as a source of inspiration and empowerment of youth culture.\\nNow as a member of the Foot Locker family, this is more evident than ever, and I see that passion in all that we do.\\nIn my short time with the company, my observations have reaffirmed my belief that this is a very special organization, one that is positioned for ongoing success and value creation.\\nIt's no secret that the retail environment is rapidly changing.\\nThe pandemic has only accelerated the change.\\nEverything from the customer journey, the process of discovery and the magnitude of digital engagement has evolved and intensified.\\nIt's clear to me that our team is focused on key initiatives that amplify the consumer experience across all of our touch points.\\nSupporting our transformative initiatives is our financial position, which is as strong as it's ever been and will allow us to remain opportunistic as we pursue our strategic plans.\\nNo doubt, there are challenges that stand before us, as well as key strategic decisions, such as the rationalization of our real estate portfolio that Dick mentioned earlier.\\nBut as we continue to emerge from the pandemic, our objectives will center around executing our growth strategy, amplifying our unique value proposition to our consumers and vendor partners and returning value to our shareholders.\\nLet me say once again: I'm glad to be here working with Dick and the broader team, and I look forward to sharing more as we continue to evolve the omnichannel retail experience for our consumers.\\nBefore we get into the numbers, I'd like to note that in addition to comparing our results to last year, I will also reference comparisons to the first quarter of 2019 where it's helpful.\\nNow let's talk about our performance in the first quarter.\\nWe delivered exceptionally strong top and bottom-line results in Q1, especially when considering the impact the pandemic continue to have on our operations.\\nOur comp sales increased 80.3% in spite of store closures in Europe and Canada and supply chain pressures in the U.S. and EMEA.\\nThe combination of robust demand for our assortment and lean with fresh inventory composition led to significantly lower levels of promotional activity this quarter.\\nAs a result, we had strong gross margin recovery compared to Q1 of 2020 as well as expansion versus Q1 of 2019.\\nThis, coupled with leverage on our SG&A expense, drove a meaningful swing in first quarter earnings per share versus last year's loss and a nearly 30% increase over Q1 of 2019.\\nTaking a closer look at our results.\\nTotal sales increased 83% over last year and 3.6% over Q1 of 2019.\\nOn a constant currency basis, sales increased 79% over Q1 of 2020.\\nThe strength was primarily driven by our stores, which increased 99%.\\nLet me remind you that our fleet was open 83% of potential operating days in the quarter versus 48% last year.\\nWhile our U.S. and Asia Pacific banners were essentially fully opened, EMEA and Canada continued to face pressure due to COVID restrictions, opened roughly 39% and 75% of potential operating days, respectively.\\nOur direct-to-consumer channel remained quite healthy as well, with sales up 47% as customers truly embraced our omnichannel offering.\\nDTC was 25% of total sales for the quarter compared to 31% last year.\\nDespite being much less promotional, average selling prices were down low single digits in the quarter, while units nearly doubled.\\nThe decline in ASP was driven primarily by product mix.\\nWe had a higher level of apparel and accessories in our mix this year versus last year.\\nIn general, apparel and accessories carry lower ASPs than footwear.\\nIn addition, we lapped last year's strong digital performance, which was heavily penetrated in footwear.\\nClicking down to our regions.\\nNorth America saw impressive growth nearly across the board, led by Champs, where comps increased triple digits.\\nThe rest of the U.S. banners follow with comps up over 90% and Foot Locker Canada posted a low 70% gain as it contended with store closures as we previously discussed.\\nEastbay was up middle single digits for the quarter, which was an improvement from recent trends.\\nThe gradual return to group sports participation sparks sales of hard goods and team performance products.\\nRecall, that unlike our other banners, Eastbay did not comp against store closures last year.\\nFoot Locker Asia delivered a triple-digit comp gain, while Foot Locker Pacific increased in the mid-90% range.\\nDespite extensive COVID restrictions, Foot Locker Europe still posted a high 30% comp increase.\\nSidestep, which experienced the most store closures, decreased in the high teens.\\nEncouragingly, the direct businesses remained very strong for both banners.\\nMoving down the income statement.\\nGross margin was 34.8% compared to 23% last year.\\nWhen compared to a more normal Q1 2019, gross margin improved 160 basis points.\\nOur merchandise margin rate improved 250 basis points over last year and 80 basis points over 2019, as the meaningful reduction in markdowns more than offset the higher freight expense that comes with increased penetration of digital sales.\\nLooking ahead, we expect the promotional environment to remain favorable through most of the year, but to a lesser extent than what we experienced in Q1.\\nAs a percent of sales, our occupancy and buyer's compensation returned to more normal levels versus last year's abnormally high rate.\\nInclusive of approximately $5 million of COVID-related rent abatements in the quarter, our occupancy costs leveraged 80 basis points over Q1 of 2019.\\nOur SG&A expense rate came in at 19.4% of sales in the quarter, as our strong sales results provided us with 750 basis points of leverage over last year and 60 basis points of leverage compared to 2019.\\nIn addition to careful expense control, we received approximately $10 million in government subsidies, which partially offset nearly $2 million of incremental PPE expense and 90 basis points of higher bonus expense.\\nFor the quarter, depreciation expense was up slightly to last year at $45 million.\\nNet interest expense increased $1 million compared to last year due to lower levels of interest income on our cash balance.\\nWe previously disclosed, given the considerable improvement in credit markets, we amended our credit facility, which will result in lower fees moving forward.\\nOur tax rate came in at 28.7% versus 22% in Q1 last year.\\nWe ended the quarter in a strong liquidity position with over $1.9 billion of cash, an increase of $951 million as of the end of Q1 last year.\\nOur higher inventory turn and slower receipt flow rate was a significant source of cash, building upon the cash we accumulated through our preservation efforts last year.\\nWe currently have no outstanding borrowings on our $600 million credit facility.\\nAt the end of Q1, inventory was down 30% compared to last year.\\nHowever, keep in mind that at the end of Q1 2020, our inventory was up 20%, which was due to the elevated store closures resulting from the pandemic.\\nWe expect our inventory levels to begin building back up in Q2.\\nWe invested approximately $51 million into our business during the quarter.\\nThis funded the opening of 12 new stores as well as the remodeling or relocating of 15 stores.\\nWe also closed 58 stores in the quarter, primarily in the U.S., leaving us with 2,952 company-owned stores at the end of Q1.\\nFor the full year, we now expect to open approximately 160 stores, remodel or relocate 120 and close 240.\\nThese amounts reflect the Footaction stores we plan to close or reposition in 2021.\\nLooking ahead, we are tracking toward approximately $275 million in capital expenditures this year, in line with our prior guidance.\\nIn terms of shareholder returns, we paid out $21 million in dividends this quarter and repurchased approximately 620,000 shares for $34 million.\\nGiven the ongoing uncertainty of the pandemic and its continued impact on our visibility across our global portfolio, we are not providing detailed guidance at this time.\\nHowever, the following directional considerations for Q2 and the full year may be helpful.\\nFor the second quarter, looking at sales, keep in mind that our comps were up nearly 19% last year in what is historically our lowest volume quarter of the year.\\nThis was due to pent-up demand, high promotional activity and government stimulus.\\nDue to delays in inventory receipts in Q1 of the current year, some sales have shifted into Q2; and as a result, we expect Q2 total sales to be relatively in line with last year.\\nWith respect to gross margin, given the level and freshness of our inventory, we expect less promotional pressure on merchandise margins as compared to Q2 last year.\\nPlease keep in mind that we face a $6 million headwind for rent abatements we obtained in Q2 last year.\\nCompared to the second quarter of 2019, we expect to see some modest gross margin expansion.\\nWith respect to SG&A, bear in mind, our strong Q2 sales last year helped to provide leverage beyond our expense management efforts.\\nWe anticipate SG&A to be elevated compared to 2020 as we lap the unique elements that benefited Q2 last year, including $17 million in government subsidies and reduced store operating costs.\\nGiven our strong start to fiscal 2021 and assuming a continued recovery from the pandemic, our current high-level expectations for the full year are as follows: total sales to increase at a low double-digit to low teens rate over fiscal 2020; meaningful gross margin expansion over fiscal 2020, largely reflecting a more rational promotional environment.\\nWhen compared to fiscal 2019, we expect to see modest gross margin improvement.\\nSG&A rates to be roughly in line with fiscal 2019.\\nLooking at our non-GAAP tax rate, for the full year, we expect it to be lower than fiscal 2020 but somewhat higher than fiscal 2019.\\n\", 'summary': 'foot locker q1 non-gaap earnings per share $1.96.\\nq1 non-gaap earnings per share $1.96.\\nq1 earnings per share $1.93.\\nq1 same store sales rose 80.3 percent.\\nfoot locker - in q2 2021, company decided to convert about one third of its footaction stores into other existing banner concepts over course of year.\\nco will close majority of remaining footaction stores as leases expire over next two years.\\nnot providing detailed full-year 2021 guidance at this time.\\n', 'input_ids': [651, 114, 446, 537, 1444, 108, 211, 2349, 5264, 195, 58655, 726, 1711, 112, 114, 1135, 446, 537, 113, 62824, 1717, 289, 232, 111, 5264, 446, 537, 113, 25348, 522, 118, 109, 211, 2349, 113, 2836, 182, 232, 131, 116, 2349, 709, 1133, 121, 12073, 2699, 113, 5886, 604, 985, 112, 109, 17460, 113, 156, 113, 109, 301, 131, 116, 9480, 4313, 108, 111, 5886, 604, 3654, 985, 112, 52363, 973, 115, 1654, 122, 109, 38771, 113, 878, 337, 2489, 107, 110, 64898, 219, 843, 108, 211, 2349, 609, 121, 53047, 5264, 195, 58655, 1717, 446, 537, 108, 114, 1225, 22898, 112, 109, 1135, 446, 537, 113, 83521, 1954, 118, 109, 211, 2349, 113, 289, 232, 111, 164, 280, 88856, 1711, 112, 5264, 446, 537, 113, 25348, 726, 118, 109, 211, 2349, 113, 2836, 184, 131, 216, 1884, 112, 133, 342, 124, 1042, 107, 2882, 2349, 108, 125, 4337, 160, 4219, 150, 7037, 30013, 7659, 107, 485, 140, 1468, 109, 437, 115, 150, 211, 2349, 107, 325, 109, 7659, 4119, 1881, 130, 109, 2349, 17077, 108, 5726, 214, 112, 1511, 3446, 349, 540, 111, 1472, 540, 602, 108, 254, 464, 109, 3121, 1628, 113, 794, 22141, 115, 1465, 111, 1493, 111, 15940, 134, 109, 475, 107, 283, 107, 7491, 108, 964, 112, 61254, 7593, 4165, 1099, 107, 651, 114, 29116, 1444, 108, 12009, 116, 7309, 16158, 224, 109, 2349, 108, 1358, 141, 150, 2062, 107, 202, 2104, 121, 21481, 116, 5088, 115, 1538, 640, 3187, 112, 2170, 3672, 9428, 111, 1035, 5218, 8488, 1422, 230, 112, 806, 7459, 121, 17586, 6602, 115, 1051, 111, 960, 130, 145, 80728, 109, 16121, 113, 109, 4585, 44078, 41428, 289, 232, 111, 109, 12071, 2145, 141, 109, 13081, 113, 150, 794, 5912, 107, 343, 150, 2062, 4706, 131, 144, 109, 209, 4135, 107, 409, 1016, 260, 163, 4615, 708, 806, 108, 164, 42547, 124, 114, 12009, 1444, 111, 5574, 134, 114, 15238, 872, 113, 8262, 113, 150, 916, 835, 108, 162, 140, 902, 197, 150, 2772, 792, 190, 109, 2349, 107, 4793, 154, 41514, 108, 254, 122, 109, 1628, 125, 2137, 108, 150, 835, 637, 140, 146, 209, 806, 4632, 112, 289, 232, 131, 116, 10131, 211, 2349, 108, 155, 163, 6075, 2706, 740, 6360, 241, 145, 1148, 580, 612, 121, 17586, 874, 6075, 114, 806, 711, 120, 232, 107, 202, 307, 92102, 111, 2921, 2510, 2994, 2059, 112, 919, 806, 1806, 482, 45449, 111, 1252, 113, 260, 107, 2113, 150, 4165, 1099, 195, 1074, 197, 145, 192, 133, 3495, 108, 109, 5349, 111, 348, 113, 2848, 140, 1163, 108, 111, 150, 2359, 6224, 221, 210, 112, 150, 6583, 9740, 116, 107, 182, 5455, 115, 902, 4165, 4272, 111, 2838, 478, 6082, 1383, 108, 5726, 214, 112, 1511, 6338, 11691, 111, 114, 1388, 2745, 1472, 121, 1803, 637, 107, 4584, 108, 145, 697, 475, 107, 283, 107, 657, 19474, 111, 1035, 16081, 735, 21676, 41161, 115, 109, 2349, 107, 182, 13523, 637, 192, 146, 133, 174, 433, 347, 149, 113, 109, 9861, 1843, 6399, 112, 109, 924, 113, 150, 301, 111, 1843, 2421, 118, 1125, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [2034, 16010, 15593, 740, 609, 121, 6438, 10384, 5264, 446, 537, 58655, 4345, 15593, 740, 609, 121, 6438, 10384, 5264, 446, 537, 58655, 4345, 15593, 740, 5264, 446, 537, 58655, 2204, 15593, 740, 310, 794, 835, 3947, 2870, 107, 726, 837, 107, 2034, 16010, 233, 115, 15593, 522, 57321, 301, 1159, 112, 4689, 160, 156, 776, 113, 203, 2034, 12242, 2062, 190, 176, 1385, 9108, 3924, 204, 422, 113, 232, 107, 1229, 138, 686, 2198, 113, 2756, 2034, 12242, 2062, 130, 24352, 16425, 204, 352, 228, 231, 107, 146, 876, 2067, 357, 121, 1019, 30013, 3090, 134, 136, 166, 107, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R592v8xV0Iy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Load the JSON files\n",
        "train_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_train.jsonl'\n",
        "val_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_val.jsonl'\n",
        "test_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_test.jsonl'\n",
        "\n",
        "# Read the JSONL files\n",
        "train_data = []\n",
        "with open(train_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        train_data.append(json.loads(line))\n",
        "\n",
        "val_data = []\n",
        "with open(val_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        val_data.append(json.loads(line))\n",
        "\n",
        "test_data = []\n",
        "with open(test_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        test_data.append(json.loads(line))\n",
        "\n",
        "# Convert to DataFrames for better handling\n",
        "train_df = pd.DataFrame(train_data)\n",
        "val_df = pd.DataFrame(val_data)\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "# Convert DataFrames to Datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "validation_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Combine the datasets for preprocessing and fine-tuning\n",
        "combined_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "# Retrieve a random sample\n",
        "random_index = random.randint(0, len(combined_df) - 1)\n",
        "initial_sample = combined_df.iloc[random_index]\n",
        "print(\"Random sample from the initial dataset (before processing):\")\n",
        "print(initial_sample)\n",
        "\n",
        "# Convert DataFrame to Dataset\n",
        "dataset = Dataset.from_pandas(combined_df)\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"google/pegasus-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Define a preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    inputs = [doc for doc in examples[\"input\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Apply the preprocessing function to the dataset\n",
        "processed_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Retrieve the processed sample\n",
        "processed_sample = processed_dataset[random_index]\n",
        "print(\"\\nRandom sample from the processed dataset (after processing):\")\n",
        "print(processed_sample)\n",
        "\n",
        "# Copy the zipped model to Google Drive with appropriate naming\n",
        "def copy_to_drive_with_naming(base_name, drive_path):\n",
        "    file_index = 0\n",
        "    while True:\n",
        "        file_name = f\"{base_name}{file_index}.zip\"\n",
        "        destination_path = os.path.join(drive_path, file_name)\n",
        "        if not os.path.exists(destination_path):\n",
        "            shutil.copyfile('model.zip', destination_path)\n",
        "            print(f\"Model saved as: {file_name}\")\n",
        "            break\n",
        "        file_index += 1\n",
        "\n",
        "# Extract the base model name and dataset short name to use as part of the base name\n",
        "base_model = model_name.split('/')[-1]  # Extract 'pegasus-large' from 'google/pegasus-large'\n",
        "dataset_short_name = \"ECTSum\"  # Shortened name for your dataset\n",
        "base_name = f\"model_{base_model}_{dataset_short_name}_\"\n",
        "copy_to_drive_path = \"/content/drive/My Drive/Models_ML2\"\n",
        "copy_to_drive_with_naming(base_name, copy_to_drive_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "0bd44ebb82d248d1af07892c361b4b0f",
            "025d0a7d2f7d41c7865bdad54ec3c59b",
            "8cff29837ebf410ea861cf0d6c8f3780",
            "85b2b2feed554d66b6b04d930d2bee1a",
            "bf9dd5fb8cc8452bb8ca27a051eb10ae",
            "8868b2f9a4054adeb6a54d22f565d007",
            "1f8df0f6bcbb4c69a6f7867e91d10d8a",
            "a3d6895ac7ac4804a876e9072a741841",
            "a936e85ea963412eaabd5d42187081ba",
            "48c6b309bd4d44d69a2819957371d9ad",
            "0cc5936166ed4eaf9d392f6658580c3e"
          ]
        },
        "id": "8laeyozSSAgw",
        "outputId": "bf2387ee-78d3-4564-8ad9-8dee6e654e28"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sample from the initial dataset (before processing):\n",
            "ticker                                                   EAT\n",
            "quarter                                                   q1\n",
            "year                                                    2021\n",
            "input      As usual, Wyman and Joe will first make prepar...\n",
            "summary    brinker international inc - qtrly net income p...\n",
            "Name: 456, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2425 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bd44ebb82d248d1af07892c361b4b0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random sample from the processed dataset (after processing):\n",
            "{'ticker': 'EAT', 'quarter': 'q1', 'year': '2021', 'input': \"As usual, Wyman and Joe will first make prepared comments related to our operating performance and strategic initiatives.\\nDuring our call, management may discuss certain items, which are not based entirely on historical facts.\\nAnd of course, on the call, we may refer to certain non-GAAP financial measures that management uses in its review of the business, and believes will provide insight into the company's ongoing operations.\\nLooking broadly at the quarter, we're encouraged by the continued improvement in the environment, the consumers increasing engagement with the category, and we hope to see those trends continue.\\nWe know there are still challenges out there, especially with independents, yet Brinker continues its strong recovery, posting a better-than-expected first quarter and also delivering earnings of $0.28 a share.\\nBoth brands increased their progression from last quarter with Chili's reporting comp sales of negative 7.2% and Maggiano's negative 38.6%.\\nAnd both brands delivered solid sequential improvement throughout the quarter, with Chili's ending September down just 1.4% and Maggiano's down 32.5%.\\nPlus casual is obviously a more challenged segment that's facing greater headwinds, but the Maggiano's team is doing a great job managing their cost structure and flow through.\\nWe feel good about where Maggiano's is from a very relative perspective, and we're excited about the bold strategy Steve Provost and the team are putting in place to build the business.\\nThe Chili's brand continues to exceed expectations from both a relative and an absolute perspective.\\nThe month of September marked our return to positive traffic, and that's pretty impressive given there are still major states like California and New Jersey, not yet near full dining room capacity.\\nThis brand continued its nearly three-year streak of outperforming other casual dining chains in KNAPP-TRACK, driving a 16-point gap in sales and 23 points in traffic this quarter.\\nWhen we broaden our view of the category to include independents, our GAAP widened significantly.\\nCurrent credit card data shows a whole category down 30%, which reflects our ongoing impact of this pandemic and the reality of what is likely to be a meaningful shift in the competitive landscape.\\nIn this tough environment, I couldn't be prouder of the resilience and agility of our operations team.\\nFor the quarter, they improved restaurant operating margin 60 basis points year over year.\\nWhen the pandemic hit back in March, the market really drove us all to dramatically cut costs.\\nSince then, we've judiciously evaluated every cost within our P&L, and we've been diligent about reestablishing our media -- our spending levels.\\nIn many cases, we're comfortable maintaining a level of spend below pre-pandemic levels.\\nOne of the biggest changes we made was to rethink our marketing spend.\\nWe significantly reduced traditional television advertising so we could invest more aggressively in digital and direct channels that work harder for us, like My Chili's Rewards.\\nAnd with the increased desire for convenience, we're shifting to support all our brands more aggressively with delivery resulting in higher third-party delivery fees and promotional expenses.\\nBased on where we're tracking with sales and the efficiency of our P&L, we feel really good about these decisions.\\nOur top priority has been and remains the safety of our team members and guests.\\nWe're committed to supporting our team that's working so hard to take care of our guests.\\nWe've now brought back most of our hourly team members, and that we've been able to help them maintain their hourly wage levels.\\nWe've also kept our management structure intact.\\nWe know how critical their leadership is to our guests and our business and we're proud that we've been able to bonus our managers close to target.\\nInstead, we leaned into the same strategies that have been helping us take share from the last three years, and they've been even more effective since the pandemic.\\nBut even before that, our challenge was to prove to ourselves and to you that we could create a growth model out of a legacy business in a category that's seen meaningful declines in traffic over the years.\\nWe have always believed growth is available in this category if you do the right things.\\nBy delivering a better guest experience, a strong value proposition and more effective marketing, we unlocked sustainable organic growth within our base business.\\nOur results demonstrate we're doing the right things.\\nOur improvements to the base enables us to introduce our first virtual brand, It's Just Wings, an incremental growth vehicle that offers convenience and value in a way no one else is positioned to do.\\nNow there's been a lot of discussion about what a virtual brand is.\\nIt's Just Wings is not a disposable vehicle.\\nWe're committed to this brand for the long haul.\\nThere are barriers to entry in doing virtual brands well, and Brinker is uniquely positioned to do it right.\\nWe have the scale, the asset ownership that's available capacity in our well-equipped kitchens, the right technology and unbelievably strong operators who can focus and deliver consistently.\\nWhen we rolled out It's Just Wings overnight to more than 1,000 restaurants.\\nNow that's easy to say, but tremendously hard to do.\\nSo I know everyone is curious about how it's going so far.\\nWe're excited with how the brand is already performing, and we're well on track to meet our first year target of more than $150 million in sales.\\nWe're encouraged by what DoorDash sees with regard to our consumer data.\\nThe brand is really generating high satisfaction scores and strong repeat usage.\\nIt's really resonating with consumers, which we know is critical to the health and long-term success of any brand.\\nGoing forward, our focus is to ensure we're executing at the highest level possible, and we're maximizing the brand's growth potential.\\nIt's Just Wings started as a virtual brand, but as we wire in the execution and accelerate growth, it may take different trajectories.\\nWe're evaluating internal and external opportunities to increase awareness levels and expand access to consumers.\\nThis is just phase I for It's Just Wings.\\nWe also believe we have capacity to expand our virtual brand portfolio.\\nWe're testing a few ideas to better understand consumer demand and ensure that we can execute at a high level.\\nWe'll have more to say on that in the not-too-distant future.\\nObviously, we see a lot of upside for virtual brands.\\nListen, with the uncertainty surrounding COVID and the economy, we anticipate some volatility ahead.\\nAnd like the rest of our country and the world, we are hoping and planning for a vaccine and an end to the sickness and deaths from this virus.\\nWe are hoping and planning for economic stability and continued recovery in the post-election environment.\\nBut despite the things no one can know, here's what we do know.\\nWe will keep running our own race and working our strategy.\\nWe will stay flexible and agile, and we'll take care of each other and our guests.\\nWe will also continue to manage our P&L and our balance sheet with discipline to create an even more stable model for our shareholders.\\nAnd we will boldly grow these brands so we can continue to be a great place for our team members to work and our shareholders to invest.\\nAnd with that, I'll turn now it over to Joe.\\nAs you just heard, we begin our fiscal year 2021 with momentum on the top and bottom line.\\nWe continued our recovery by delivering adjusted diluted earnings per share of positive $0.28, marking the return to profitability after just a one quarter hiatus.\\nNow for the quarter, Brinker's total revenues were $740 million and consolidated reported net comp sales were negative 10.9%.\\nImportantly, comp sales materially improved as the quarter progressed, with September consolidated comp sales down only 5.2%.\\nChili's has continued to lead the casual dining sector, ranking as the #1 brand in the KNAPP-TRACK index each month in this quarter.\\nAnd as Wyman indicated, beat by significant margins in both sales and traffic.\\nIn September, Chili's achieved another important milestone in its recovery, posting positive traffic for the brand of 2.2%.\\nAnother way to see Chili's impressive progression is to look at our net comp sales results, excluding those restaurants and markets not fully open for our indoor dining during the quarter, such as California and New Jersey.\\nThese restaurants represent approximately 86% of the Chili's system, and they were only negative 1.3% for the quarter and positive 3.6% for September.\\nNow turning to margins.\\nRestaurant operating margin for the first quarter was 11.6%, a noteworthy 60 basis points improvement versus prior year.\\nFood and beverage expenses were favorable 10 basis points versus prior year due to the favorable menu mix, offset by low level of commodity inflation.\\nLabor was also favorable 120 basis points versus prior year.\\nNow several items contributed to this improved performance.\\nFirst, labor expense relative to prior year benefited from the shift in sales from dine-in to off-premise in the quarter.\\nSecond, favorability was also buoyed by the fact some of our higher labor cost states reopened at a slower pace during the recovery, a benefit that will diminish as we move forward.\\nOf course, naturally, we'll take the sales that go with adding that labor back into the equation.\\nAnd finally, labor expense benefited from the ability to seamlessly integrate our It's Just Wings brand into the existing labor model, a point of leverage and we plan to sustain.\\nThe labor favorability was partially offset by the increase in restaurant expenses, which was up 70 basis points for the first quarter versus prior year.\\nSales to leverage, higher delivery related fees and packaging expense were the primary increases, while lower advertising and repairs and maintenance expenses helped mitigate the overall increase.\\nGenerating positive cash flow is an important part of our recovery process.\\nWith the business improving, we generated operating cash flow of $83 million.\\nAfter capital expenditures of the approximately $14 million, our free cash flow for the quarter totaled more than $69 million.\\nOur first priority for cash generation is to invest back in the business.\\nAnd as such, we have resumed both restaurant reimages and new restaurant development.\\nWe have increased our capex budget for the year and now expect to spend approximately $100 million during this fiscal year.\\nAs Wyman reiterated, strengthening the balance sheet is also a key area of focus for us.\\nAs such, our second cash priority is to pay down debt, and we executed against this strategy during the quarter, reducing our long-term debt by approximately $50 million.\\nWe will continue to lower leverage as we move forward from here targeting an adjusted debt level of about 3.5 times EBITDAR.\\nNow turning to our current second quarter.\\nLet me provide some color as to our expectations for the quarter and then some specific guidance metrics for the quarter.\\nToday marks the end of our October period, and it appears we will continue the positive progression of comp sales established during the first quarter.\\nWe expect Chili's to further build its positive traffic performance this period, getting the second quarter off to a very fine start.\\nWhile we anticipate year over year improvements in Chile's operating performance in the second quarter, our consolidated performance will likely reflect a more difficult holiday environment for the Maggiano's brand.\\nWith that being said, let me provide some specifics for Brinker's performance in the second quarter.\\nWe expect consolidated comp store sales to be down in the mid single-digit range.\\nWe believe Brinker's restaurant operating margins will be relatively similar to prior year.\\nAdjusted earnings per diluted share are estimated to be in the range of $0.40 to $0.60 and weighted average diluted shares are estimated to be in the 45 million to 46 million share range.\\nI would also note we have the holiday flip in the second quarter with Christmas Eve and Christmas Day moving into the third quarter.\\nThis holiday shift will have a positive impact to second quarter comp sales that will be offset in the first period of Q3.\\nDespite the ongoing challenges in our operating environment, we continue to demonstrate strength and resilience.\\nSo, our first quarter performance is a testament to our ability to deliver results.\\nWhile operating in a pandemic environment comes with some uncertainties, there is no doubt we will continue to execute our share gaining strategy, take care of our guests and team members and be a leader in the restaurant industry for the short and long term.\\n\", 'summary': \"brinker international inc - qtrly net income per diluted share, excluding special items $0.28.\\nbrinker international inc - chilis total comparable restaurant sales decreased 7.2% in q1 21.\\nbrinker international inc - maggiano's total comparable restaurant sales decreased 38.6% in q1 21.\\nbrinker international inc - for q2 21 net income per diluted share, excluding special items, expected to be $0.40 to $0.60.\\n\", 'input_ids': [398, 2985, 108, 83127, 111, 3883, 138, 211, 193, 1831, 1770, 985, 112, 150, 1901, 637, 111, 3112, 4417, 107, 2348, 150, 443, 108, 603, 218, 1693, 878, 843, 108, 162, 127, 146, 451, 3143, 124, 2876, 4008, 107, 325, 113, 422, 108, 124, 109, 443, 108, 145, 218, 3984, 112, 878, 609, 121, 53047, 748, 2548, 120, 603, 1481, 115, 203, 933, 113, 109, 260, 108, 111, 3999, 138, 319, 3963, 190, 109, 301, 131, 116, 3121, 1875, 107, 4395, 14900, 134, 109, 2349, 108, 145, 131, 216, 3825, 141, 109, 2059, 2757, 115, 109, 849, 108, 109, 2359, 2186, 2914, 122, 109, 2152, 108, 111, 145, 715, 112, 236, 274, 2994, 801, 107, 184, 235, 186, 127, 309, 1628, 165, 186, 108, 704, 122, 1991, 116, 108, 610, 56416, 420, 2138, 203, 806, 2597, 108, 3906, 114, 340, 121, 10306, 121, 37254, 211, 2349, 111, 163, 3827, 5264, 113, 68856, 2000, 114, 537, 107, 2595, 2164, 1562, 153, 8973, 135, 289, 2349, 122, 28534, 131, 116, 3234, 12009, 835, 113, 2404, 110, 80482, 111, 67123, 8441, 131, 116, 2404, 296, 74760, 107, 325, 302, 2164, 2336, 1907, 29116, 2757, 720, 109, 2349, 108, 122, 28534, 131, 116, 4439, 1338, 308, 188, 110, 56069, 111, 67123, 8441, 131, 116, 308, 296, 70534, 107, 2596, 5048, 117, 4368, 114, 154, 8043, 5125, 120, 131, 116, 2931, 1626, 71915, 108, 155, 109, 67123, 8441, 131, 116, 320, 117, 557, 114, 255, 494, 3136, 153, 519, 1557, 111, 1971, 224, 107, 184, 393, 234, 160, 241, 67123, 8441, 131, 116, 117, 135, 114, 221, 4632, 2708, 108, 111, 145, 131, 216, 1884, 160, 109, 4964, 1520, 3948, 44206, 111, 109, 320, 127, 2193, 115, 295, 112, 736, 109, 260, 107, 139, 28534, 131, 116, 789, 2138, 112, 6264, 2772, 135, 302, 114, 4632, 111, 142, 4448, 2708, 107, 139, 625, 113, 1338, 4246, 150, 935, 112, 1259, 1619, 108, 111, 120, 131, 116, 848, 2745, 634, 186, 127, 309, 698, 1653, 172, 1310, 111, 351, 3477, 108, 146, 610, 828, 357, 1691, 418, 1865, 107, 182, 789, 2059, 203, 1517, 339, 121, 1019, 11102, 113, 71717, 176, 5048, 1691, 8700, 115, 44713, 29507, 121, 50842, 108, 1528, 114, 13296, 4668, 4215, 115, 835, 111, 2412, 884, 115, 1619, 136, 2349, 107, 434, 145, 18889, 150, 700, 113, 109, 2152, 112, 444, 1991, 116, 108, 150, 57501, 39869, 2838, 107, 8708, 910, 752, 335, 939, 114, 664, 2152, 308, 7732, 108, 162, 6389, 150, 3121, 979, 113, 136, 41428, 111, 109, 1980, 113, 180, 117, 770, 112, 129, 114, 4773, 3460, 115, 109, 2290, 2646, 107, 222, 136, 2658, 849, 108, 125, 1826, 131, 144, 129, 2038, 420, 113, 109, 11951, 111, 17239, 113, 150, 1875, 320, 107, 321, 109, 2349, 108, 157, 2521, 1705, 1901, 7711, 1790, 1444, 884, 232, 204, 232, 107, 434, 109, 41428, 1194, 247, 115, 1051, 108, 109, 407, 288, 6192, 214, 149, 112, 7309, 999, 973, 107, 1685, 237, 108, 145, 131, 261, 87959, 8905, 290, 519, 373, 150, 881, 759, 1240, 108, 111, 145, 131, 261, 174, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [27419, 420, 942, 26805, 233, 39405, 551, 445, 2677, 1643, 446, 24672, 537, 108, 17565, 548, 843, 68856, 5949, 27419, 420, 942, 26805, 233, 11985, 116, 916, 8575, 1705, 835, 8408, 110, 80482, 115, 15593, 740, 1616, 107, 27419, 420, 942, 26805, 233, 15842, 838, 29517, 131, 116, 916, 8575, 1705, 835, 8408, 296, 74760, 115, 15593, 740, 1616, 107, 27419, 420, 942, 26805, 233, 118, 15593, 522, 1616, 2677, 1643, 446, 24672, 537, 108, 17565, 548, 843, 108, 1214, 112, 129, 72323, 3142, 112, 83521, 24613, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "Model saved as: model_pegasus-large_ECTSum_1.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Data"
      ],
      "metadata": {
        "id": "nmRjZMRgqquU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(train_dataset.column_names)\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "validation_dataset = validation_dataset.map(preprocess_function, batched=True)\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "c03f197452844740893645316b4a5c15",
            "0726f9417ff04970a32fae1c0d6b8a37",
            "e32d48245d00400a8a89c2a3aa761f4b",
            "758b268fa7004c0f88f856636d03ac8d",
            "d2ab4cd8cdd340829a4fb960f2a0599c",
            "27a99990a6e34653b841c7c792c0648e",
            "0a54481688af441d911ba69823d9cbc3",
            "507cf50f044c4290a053d8b1d1ea823e",
            "2aa3bc704cc3493db37f84502d72efd6",
            "bb86e46d37454d3f9d18eb6eed96bc24",
            "da0134ef40114f9a9c1c7da334eb4dd8",
            "f02a77ca3f474c6396a21281aa6d7a15",
            "822cfd80efbd43e19462bbaa860415e6",
            "bd0bd757fe1f4df286ec9fdca2bcd300",
            "5495c37bd4bb4b3db207cec64bac976c",
            "2fa7073862544a94ad5cdfa1bd834588",
            "ca2477e11e42450cb66a36c42f996c3f",
            "e710fc2b0504465eb0a873e98062de36",
            "662659310b424c48bd1e30f3a5612d82",
            "33b992f8f71d46ba8d8ca7bcaa152ebc",
            "7a7643359b004b1792f80399cf1641eb",
            "4323720d62fd446e9bd36ed9cab16700",
            "437b41c9c5474661b2e3a6a77a53b423",
            "b24a2164b3bd486692c111cb50c3cb8c",
            "86f804f954894b0a800a115459b4575a",
            "eda5fae782c64c4fb4db441baaaf77bd",
            "d647088129124736b28e991765a41d4a",
            "2ca8256b94e74654a1498595f98144d3",
            "71ddeaa0f9f2438b83024542f50e826c",
            "a0749dedfafd415cb11918a0feb2e1a7",
            "031cfe2307f948b5ad91eb77917e2294",
            "49c315eb6b1d4f9590124f213681ecac",
            "9f38febe619045f1982bc3dc709db048"
          ]
        },
        "id": "lVcSa16gy9f0",
        "outputId": "98c468b2-7b8a-4c34-d75a-40b4ffdead6b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ticker', 'quarter', 'year', 'input', 'summary']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1681 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c03f197452844740893645316b4a5c15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/249 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f02a77ca3f474c6396a21281aa6d7a15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/495 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "437b41c9c5474661b2e3a6a77a53b423"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample after"
      ],
      "metadata": {
        "id": "0nt250Ur0GSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inspect a random sample from the preprocessed dataset\n",
        "random_index = random.randint(0, len(train_dataset) - 1)\n",
        "preprocessed_sample = train_dataset[random_index]\n",
        "print(\"Random sample from the preprocessed dataset:\")\n",
        "print(pd.DataFrame([preprocessed_sample]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z99shmJj0QYV",
        "outputId": "b4821e63-b735-4752-a6c5-a9a7981239db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sample from the preprocessed dataset:\n",
            "  ticker quarter  year                                              input  \\\n",
            "0    JBL      q3  2021  To follow along with slides, please visit jabi...   \n",
            "\n",
            "                                             summary  \\\n",
            "0  compname posts q3 gaap earnings per share $1.1...   \n",
            "\n",
            "                                           input_ids  \\\n",
            "0  [413, 857, 466, 122, 9538, 108, 528, 558, 3995...   \n",
            "\n",
            "                                      attention_mask  \\\n",
            "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
            "\n",
            "                                              labels  \n",
            "0  [12009, 7982, 2131, 15593, 726, 17031, 10384, ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Preprocess the data\n",
        "# def preprocess_function(examples):\n",
        "#     inputs = [doc for doc in examples[\"article\"]]\n",
        "#     model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")  # Reduced max_length\n",
        "#     labels = tokenizer(text_target=examples[\"highlights\"], max_length=128, truncation=True, padding=\"max_length\")\n",
        "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "#     return model_inputs\n",
        "\n",
        "# train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "# validation_dataset = validation_dataset.map(preprocess_function, batched=True)\n",
        "# test_dataset = test_dataset.map(preprocess_function, batched=True)\n"
      ],
      "metadata": {
        "id": "WhDaLUkiqsmX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use DataCollatorForSeq2Seq to handle padding\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
      ],
      "metadata": {
        "id": "9ANJhsYYqxu1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **training**"
      ],
      "metadata": {
        "id": "6TStzNuYozsv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AtRRpUdhtqOB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training / modeling part.... //"
      ],
      "metadata": {
        "id": "ixb3dhF1q0t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments with mixed precision and gradient accumulation\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,  # Adjust batch size if necessary\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=12,  # Increase number of epochs for better learning\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,  # Enable mixed precision training\n",
        "    gradient_accumulation_steps=2,  # Accumulate gradients over 2 steps\n",
        "    logging_steps=100,  # Reduce logging frequency\n",
        "    save_steps=500,  # Adjust save steps\n",
        "    evaluation_strategy=\"steps\",  # Evaluate every save step\n",
        "    eval_steps=500,  # Adjust evaluation steps\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8XU3ZA5q2Xw",
        "outputId": "4ea804cd-aadc-40cd-f58c-cad7f6d5a997"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #done for project: (just better more computing power)\n",
        "# # Define training arguments with mixed precision and gradient accumulation\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./results\",\n",
        "#     learning_rate=2e-5,\n",
        "#     per_device_train_batch_size=8,  # Adjust batch size if necessary\n",
        "#     per_device_eval_batch_size=8,\n",
        "#     num_train_epochs=3,  # Increase number of epochs for better learning\n",
        "#     weight_decay=0.01,\n",
        "#     fp16=True,  # Enable mixed precision training\n",
        "#     gradient_accumulation_steps=2,  # Accumulate gradients over 2 steps\n",
        "#     logging_steps=100,  # Reduce logging frequency\n",
        "#     save_steps=500,  # Adjust save steps\n",
        "#     evaluation_strategy=\"steps\",  # Evaluate every save step\n",
        "#     eval_steps=500,  # Adjust evaluation steps\n",
        "#     load_best_model_at_end=True,\n",
        "#     metric_for_best_model=\"eval_loss\",\n",
        "# )\n"
      ],
      "metadata": {
        "id": "Djq0_YwjtUJW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ],
      "metadata": {
        "id": "JfvNAGeJq6AR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
      ],
      "metadata": {
        "id": "Dv1mryHV1Hip"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checks:"
      ],
      "metadata": {
        "id": "xDOROQrtq_tV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "to do parameter finetuning and: Instruction Tuning is Key: For zero-shot summarization tasks, instruction tuning significantly outperforms mere model scaling."
      ],
      "metadata": {
        "id": "BBD3gKuIvp_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure model is on the correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqiKqTVyrB9I",
        "outputId": "80b83693-289d-4394-a244-702db37a2955"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PegasusForConditionalGeneration(\n",
              "  (model): PegasusModel(\n",
              "    (shared): Embedding(96103, 1024, padding_idx=0)\n",
              "    (encoder): PegasusEncoder(\n",
              "      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
              "      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-15): 16 x PegasusEncoderLayer(\n",
              "          (self_attn): PegasusAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): ReLU()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): PegasusDecoder(\n",
              "      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
              "      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-15): 16 x PegasusDecoderLayer(\n",
              "          (self_attn): PegasusAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): ReLU()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): PegasusAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "GJ80W8_HrHFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "wtf comp to other"
      ],
      "metadata": {
        "id": "ulPl0UwPwNSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=processed_dataset,\n",
        "    eval_dataset=processed_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "teNrmYwPrGT5",
        "outputId": "918b6d36-2ee8-4896-ffa5-b73b69651156"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1824' max='1824' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1824/1824 15:11, Epoch 12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.756400</td>\n",
              "      <td>1.102212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.881000</td>\n",
              "      <td>0.765896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.823100</td>\n",
              "      <td>0.735025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 256, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 256, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 256, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n",
            "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1824, training_loss=2.121599143011528, metrics={'train_runtime': 913.1352, 'train_samples_per_second': 31.868, 'train_steps_per_second': 1.998, 'total_flos': 4.20417072267264e+16, 'train_loss': 2.121599143011528, 'epoch': 12.0})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vorlage:"
      ],
      "metadata": {
        "id": "iY1v3uW0pxyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the Save Path\n",
        "drive_save_path = '/content/drive/My Drive/fine_tuned_model'\n",
        "\n",
        "# Load the pretrained model and tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig\n",
        "\n",
        "model_name = \"google/pegasus-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Assume `model` is your fine-tuned model and `tokenizer` is your tokenizer\n",
        "# Define the local directory to save the fine-tuned model and tokenizer\n",
        "fine_tuned_directory = \"./results\"\n",
        "\n",
        "# Save the fine-tuned model and tokenizer to the local directory\n",
        "model.save_pretrained(fine_tuned_directory)\n",
        "tokenizer.save_pretrained(fine_tuned_directory)\n",
        "\n",
        "# Optionally, save the generation configuration if used\n",
        "gen_config = GenerationConfig(\n",
        "    max_length=142,\n",
        "    min_length=56,\n",
        "    early_stopping=True,\n",
        "    num_beams=4,\n",
        "    length_penalty=2.0,\n",
        "    no_repeat_ngram_size=3,\n",
        "    forced_bos_token_id=0,\n",
        "    forced_eos_token_id=2\n",
        ")\n",
        "gen_config.save_pretrained(fine_tuned_directory)\n",
        "# Print all files in the fine-tuned directory to ensure they are saved\n",
        "print(\"Files in the fine-tuned directory:\")\n",
        "for root, dirs, files in os.walk(fine_tuned_directory):\n",
        "    for filename in files:\n",
        "        print(os.path.join(root, filename))\n",
        "\n",
        "# List of files to keep (fine-tuned files)\n",
        "files_to_keep = [\n",
        "    \"config.json\",\n",
        "    \"generation_config.json\",\n",
        "    \"model.safetensors\",  # or 'pytorch_model.bin'\n",
        "    \"special_tokens_map.json\",\n",
        "    \"spiece.model\",\n",
        "    \"tokenizer.json\",\n",
        "    \"tokenizer_config.json\"\n",
        "]\n",
        "\n",
        "# Print all files in the fine-tuned directory to ensure they are saved\n",
        "print(\"Files in the fine-tuned directory:\")\n",
        "for root, dirs, files in os.walk(fine_tuned_directory):\n",
        "    for filename in files:\n",
        "        print(os.path.join(root, filename))\n",
        "\n",
        "# Step 4: Copy Only Fine-Tuned Files to Google Drive\n",
        "# If the directory exists, delete it first\n",
        "if os.path.exists(drive_save_path):\n",
        "    shutil.rmtree(drive_save_path)\n",
        "\n",
        "# Create the directory in Google Drive\n",
        "os.makedirs(drive_save_path)\n",
        "\n",
        "# Copy only the necessary files to Google Drive\n",
        "for file_name in files_to_keep:\n",
        "    src_path = os.path.join(fine_tuned_directory, file_name)\n",
        "    dest_path = os.path.join(drive_save_path, file_name)\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.copy(src_path, dest_path)\n",
        "        print(f\"Copied {src_path} to {dest_path}\")\n",
        "    else:\n",
        "        print(f\"{src_path} does not exist\")\n",
        "\n",
        "# Print all files in the Google Drive save directory to ensure they are saved\n",
        "print(\"Files in the Google Drive save directory:\")\n",
        "for root, dirs, files in os.walk(drive_save_path):\n",
        "    for filename in files:\n",
        "        print(os.path.join(root, filename))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLmftWoWLnZY",
        "outputId": "2a692ac0-5e70-4c5d-8e6b-6126d7c97a83"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 256, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the fine-tuned directory:\n",
            "./results/config.json\n",
            "./results/model.safetensors\n",
            "./results/tokenizer.json\n",
            "./results/spiece.model\n",
            "./results/special_tokens_map.json\n",
            "./results/tokenizer_config.json\n",
            "./results/generation_config.json\n",
            "./results/checkpoint-500/config.json\n",
            "./results/checkpoint-500/model.safetensors\n",
            "./results/checkpoint-500/trainer_state.json\n",
            "./results/checkpoint-500/optimizer.pt\n",
            "./results/checkpoint-500/training_args.bin\n",
            "./results/checkpoint-500/scheduler.pt\n",
            "./results/checkpoint-500/generation_config.json\n",
            "./results/checkpoint-500/rng_state.pth\n",
            "./results/checkpoint-1000/config.json\n",
            "./results/checkpoint-1000/model.safetensors\n",
            "./results/checkpoint-1000/trainer_state.json\n",
            "./results/checkpoint-1000/optimizer.pt\n",
            "./results/checkpoint-1000/training_args.bin\n",
            "./results/checkpoint-1000/scheduler.pt\n",
            "./results/checkpoint-1000/generation_config.json\n",
            "./results/checkpoint-1000/rng_state.pth\n",
            "./results/checkpoint-1500/config.json\n",
            "./results/checkpoint-1500/model.safetensors\n",
            "./results/checkpoint-1500/trainer_state.json\n",
            "./results/checkpoint-1500/optimizer.pt\n",
            "./results/checkpoint-1500/training_args.bin\n",
            "./results/checkpoint-1500/scheduler.pt\n",
            "./results/checkpoint-1500/generation_config.json\n",
            "./results/checkpoint-1500/rng_state.pth\n",
            "./results/runs/Jun08_18-31-55_834c0497bd01/events.out.tfevents.1717871517.834c0497bd01.1116.0\n",
            "Files in the fine-tuned directory:\n",
            "./results/config.json\n",
            "./results/model.safetensors\n",
            "./results/tokenizer.json\n",
            "./results/spiece.model\n",
            "./results/special_tokens_map.json\n",
            "./results/tokenizer_config.json\n",
            "./results/generation_config.json\n",
            "./results/checkpoint-500/config.json\n",
            "./results/checkpoint-500/model.safetensors\n",
            "./results/checkpoint-500/trainer_state.json\n",
            "./results/checkpoint-500/optimizer.pt\n",
            "./results/checkpoint-500/training_args.bin\n",
            "./results/checkpoint-500/scheduler.pt\n",
            "./results/checkpoint-500/generation_config.json\n",
            "./results/checkpoint-500/rng_state.pth\n",
            "./results/checkpoint-1000/config.json\n",
            "./results/checkpoint-1000/model.safetensors\n",
            "./results/checkpoint-1000/trainer_state.json\n",
            "./results/checkpoint-1000/optimizer.pt\n",
            "./results/checkpoint-1000/training_args.bin\n",
            "./results/checkpoint-1000/scheduler.pt\n",
            "./results/checkpoint-1000/generation_config.json\n",
            "./results/checkpoint-1000/rng_state.pth\n",
            "./results/checkpoint-1500/config.json\n",
            "./results/checkpoint-1500/model.safetensors\n",
            "./results/checkpoint-1500/trainer_state.json\n",
            "./results/checkpoint-1500/optimizer.pt\n",
            "./results/checkpoint-1500/training_args.bin\n",
            "./results/checkpoint-1500/scheduler.pt\n",
            "./results/checkpoint-1500/generation_config.json\n",
            "./results/checkpoint-1500/rng_state.pth\n",
            "./results/runs/Jun08_18-31-55_834c0497bd01/events.out.tfevents.1717871517.834c0497bd01.1116.0\n",
            "Copied ./results/config.json to /content/drive/My Drive/fine_tuned_model/config.json\n",
            "Copied ./results/generation_config.json to /content/drive/My Drive/fine_tuned_model/generation_config.json\n",
            "Copied ./results/model.safetensors to /content/drive/My Drive/fine_tuned_model/model.safetensors\n",
            "Copied ./results/special_tokens_map.json to /content/drive/My Drive/fine_tuned_model/special_tokens_map.json\n",
            "Copied ./results/spiece.model to /content/drive/My Drive/fine_tuned_model/spiece.model\n",
            "Copied ./results/tokenizer.json to /content/drive/My Drive/fine_tuned_model/tokenizer.json\n",
            "Copied ./results/tokenizer_config.json to /content/drive/My Drive/fine_tuned_model/tokenizer_config.json\n",
            "Files in the Google Drive save directory:\n",
            "/content/drive/My Drive/fine_tuned_model/config.json\n",
            "/content/drive/My Drive/fine_tuned_model/generation_config.json\n",
            "/content/drive/My Drive/fine_tuned_model/model.safetensors\n",
            "/content/drive/My Drive/fine_tuned_model/special_tokens_map.json\n",
            "/content/drive/My Drive/fine_tuned_model/spiece.model\n",
            "/content/drive/My Drive/fine_tuned_model/tokenizer.json\n",
            "/content/drive/My Drive/fine_tuned_model/tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zAAMbfJ2p0D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the versions of transformers, accelerate, and torch\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "print(\"Accelerate version:\", accelerate.__version__)\n",
        "print(\"Torch version:\", torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ2PdOyKo7Tx",
        "outputId": "35f53177-dc4c-463b-8f01-d2a2dafe687f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version: 4.41.2\n",
            "Accelerate version: 0.31.0\n",
            "Torch version: 2.3.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrjWzbPXqGgT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**evaluation**"
      ],
      "metadata": {
        "id": "7NetgMjBo9HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model (short overvie numbers)\n",
        "metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "0uUPs23Ertyw",
        "outputId": "431c678c-84be-405f-a836-003436d3bf6f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [62/62 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7254868149757385, 'eval_runtime': 3.7487, 'eval_samples_per_second': 132.047, 'eval_steps_per_second': 16.539, 'epoch': 12.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Configuaration from finetiuned /tempraus"
      ],
      "metadata": {
        "id": "iZP4F_Dt_hpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries for evaluation"
      ],
      "metadata": {
        "id": "p0l9HRHhpI_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATION CURRENTLY WRONG"
      ],
      "metadata": {
        "id": "3gnF9pF5r-yC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpS3OyMPo_9y",
        "outputId": "2cda6bf3-b92f-4aac-8832-803525228a7c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=1b367a226aa68531627df073242a63196ac12a3b07990d683fc58d3af6f2f9ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score, evaluate\n",
            "Successfully installed evaluate-0.4.2 rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try Out:"
      ],
      "metadata": {
        "id": "B98xfUsIxCIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Load the pretrained model and tokenizer\n",
        "model_name = \"google/pegasus-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"\n",
        "The fake industrial Revolution was a period of major industrialization and innovation that took place during the late 1700s and early 1800s. It began in Great Britain and quickly spread throughout the world. This period marked a significant turning point in history; almost every aspect of daily life was influenced in some way. Improvements in farming techniques and livestock breeding led to increased food production and the rise of the steam engine. The rise of factories created a new class of wealthy industrialists and businessmen, but also created social tensions and unrest. Despite many challenges and hardships, the Industrial Revolution was a period of significant change and transformation, paving the way for the modern industrial economy.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "# Generate summary\n",
        "summary_ids = model.generate(inputs[\"input_ids\"], max_length=142, min_length=56, early_stopping=True, num_beams=4, length_penalty=2.0, no_repeat_ngram_size=3)\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URJsqP0oxEZg",
        "outputId": "83adfe44-0e4c-47b4-bbce-5dc26d44ecb2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This period marked a significant turning point in history; almost every aspect of daily life was influenced in some way. Despite many challenges and hardships, the Industrial Revolution was a period of significant change and transformation, paving the way for the modern industrial economy. The rise of factories created a new class of wealthy industrialists and businessmen, but also created social tensions and unrest. Improvements in farming techniques and livestock breeding led to increased food production and the rise of the steam engine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "try out with paths"
      ],
      "metadata": {
        "id": "HFNmibDEAm0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Load the pretrained model and tokenizer\n",
        "model_name = \"google/pegasus-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"\n",
        "The fake industrial Revolution was a period of major industrialization and innovation that took place during the late 1700s and early 1800s. It began in Great Britain and quickly spread throughout the world. This period marked a significant turning point in history; almost every aspect of daily life was influenced in some way. Improvements in farming techniques and livestock breeding led to increased food production and the rise of the steam engine. The rise of factories created a new class of wealthy industrialists and businessmen, but also created social tensions and unrest. Despite many challenges and hardships, the Industrial Revolution was a period of significant change and transformation, paving the way for the modern industrial economy.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "# Generate summary\n",
        "summary_ids = model.generate(inputs[\"input_ids\"], max_length=142, min_length=56, early_stopping=True, num_beams=4, length_penalty=2.0, no_repeat_ngram_size=3)\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(summary)\n",
        "\n",
        "# # Print all files in the current directory\n",
        "# print(\"Files in the current directory:\")\n",
        "# for root, dirs, files in os.walk(\".\"):\n",
        "#     for filename in files:\n",
        "#         print(os.path.join(root, filename))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5S0ku0RAl3e",
        "outputId": "f55017cc-e5ec-430d-9b34-60e2ef791b0a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This period marked a significant turning point in history; almost every aspect of daily life was influenced in some way. Despite many challenges and hardships, the Industrial Revolution was a period of significant change and transformation, paving the way for the modern industrial economy. The rise of factories created a new class of wealthy industrialists and businessmen, but also created social tensions and unrest. Improvements in farming techniques and livestock breeding led to increased food production and the rise of the steam engine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Print all files in the results directory\n",
        "print(\"Files in the results directory:\")\n",
        "for root, dirs, files in os.walk(\"./results\"):\n",
        "    for filename in files:\n",
        "        print(os.path.join(root, filename))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mwc6DsfBwJh",
        "outputId": "db6207bc-fbe8-4bde-a10b-bdc23d6cef95"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the results directory:\n",
            "./results/config.json\n",
            "./results/model.safetensors\n",
            "./results/tokenizer.json\n",
            "./results/spiece.model\n",
            "./results/special_tokens_map.json\n",
            "./results/tokenizer_config.json\n",
            "./results/generation_config.json\n",
            "./results/checkpoint-500/config.json\n",
            "./results/checkpoint-500/model.safetensors\n",
            "./results/checkpoint-500/trainer_state.json\n",
            "./results/checkpoint-500/optimizer.pt\n",
            "./results/checkpoint-500/training_args.bin\n",
            "./results/checkpoint-500/scheduler.pt\n",
            "./results/checkpoint-500/generation_config.json\n",
            "./results/checkpoint-500/rng_state.pth\n",
            "./results/checkpoint-1000/config.json\n",
            "./results/checkpoint-1000/model.safetensors\n",
            "./results/checkpoint-1000/trainer_state.json\n",
            "./results/checkpoint-1000/optimizer.pt\n",
            "./results/checkpoint-1000/training_args.bin\n",
            "./results/checkpoint-1000/scheduler.pt\n",
            "./results/checkpoint-1000/generation_config.json\n",
            "./results/checkpoint-1000/rng_state.pth\n",
            "./results/checkpoint-1500/config.json\n",
            "./results/checkpoint-1500/model.safetensors\n",
            "./results/checkpoint-1500/trainer_state.json\n",
            "./results/checkpoint-1500/optimizer.pt\n",
            "./results/checkpoint-1500/training_args.bin\n",
            "./results/checkpoint-1500/scheduler.pt\n",
            "./results/checkpoint-1500/generation_config.json\n",
            "./results/checkpoint-1500/rng_state.pth\n",
            "./results/runs/Jun08_18-31-55_834c0497bd01/events.out.tfevents.1717872458.834c0497bd01.1116.1\n",
            "./results/runs/Jun08_18-31-55_834c0497bd01/events.out.tfevents.1717871517.834c0497bd01.1116.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_directory = \"./results\"  # Path to your fine-tuned model directory\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_directory)\n",
        "gen_config = GenerationConfig.from_pretrained(model_directory)\n",
        "\n",
        "# Set decoder_start_token_id if not already set\n",
        "if gen_config.decoder_start_token_id is None:\n",
        "    gen_config.decoder_start_token_id = model.config.decoder_start_token_id\n",
        "if gen_config.bos_token_id is None:\n",
        "    gen_config.bos_token_id = model.config.bos_token_id\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"\n",
        "The Industrial Revolution was a period of major industrialization and innovation that took place during the late 1700s and early 1800s. It began in Great Britain and quickly spread throughout the world. This period marked a significant turning point in history; almost every aspect of daily life was influenced in some way. Improvements in farming techniques and livestock breeding led to increased food production and the rise of the steam engine. The rise of factories created a new class of wealthy industrialists and businessmen, but also created social tensions and unrest. Despite many challenges and hardships, the Industrial Revolution was a period of significant change and transformation, paving the way for the modern industrial economy.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "# Generate summary using fine-tuned model\n",
        "summary_ids = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    max_length=gen_config.max_length,\n",
        "    min_length=gen_config.min_length,\n",
        "    early_stopping=gen_config.early_stopping,\n",
        "    num_beams=gen_config.num_beams,\n",
        "    length_penalty=gen_config.length_penalty,\n",
        "    no_repeat_ngram_size=gen_config.no_repeat_ngram_size,\n",
        "    forced_bos_token_id=gen_config.forced_bos_token_id,\n",
        "    forced_eos_token_id=gen_config.forced_eos_token_id,\n",
        "    decoder_start_token_id=gen_config.decoder_start_token_id,\n",
        "    bos_token_id=gen_config.bos_token_id\n",
        ")\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cMhMKpVxTNV",
        "outputId": "4aef499e-9443-4938-bcce-9bfd3894c7fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This period marked a significant turning point in history; almost every aspect of daily life was influenced in some way. Despite many challenges and hardships, the Industrial Revolution was a period of significant change and transformation, paving the way for the modern industrial economy.The Industrial Revolution began in the late 1700s and early 1800s. The Industrial Revolution is the period of major industrialization and innovation that began in Great Britain and quickly spread throughout the world.Despite many challenges, hardships and changes in the industrial economy, the industrial revolution was a significant period of change, transformation and innovation.The industrial revolution began in Britain in the early 1700s, and has since spread throughout Europe and the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "do some kind of check / just numbers not whole valuation"
      ],
      "metadata": {
        "id": "OrzngcKLxURa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finishing Project Steps / Model Storage etc: no need to execute"
      ],
      "metadata": {
        "id": "Y2OwD-pxr4iT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and tokenizer\n",
        "model.save_pretrained('./results')\n",
        "tokenizer.save_pretrained('./results')\n",
        "gen_config = GenerationConfig(\n",
        "    max_length=142,\n",
        "    min_length=56,\n",
        "    early_stopping=True,\n",
        "    num_beams=4,\n",
        "    length_penalty=2.0,\n",
        "    no_repeat_ngram_size=3,\n",
        "    forced_bos_token_id=0,\n",
        "    forced_eos_token_id=2\n",
        ")\n",
        "gen_config.save_pretrained(fine_tuned_directory)\n",
        "\n",
        "# Print all files in the fine-tuned directory to ensure they are saved\n",
        "print(\"Files in the fine-tuned directory:\")\n",
        "for root, dirs, files in os.walk(fine_tuned_directory):\n",
        "    for filename in files:\n",
        "        print(os.path.join(root, filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8kfdqlOpBlJ",
        "outputId": "9b60d316-2651-4875-9f5b-f68ace874134"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 256, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the fine-tuned directory:\n",
            "./results/config.json\n",
            "./results/model.safetensors\n",
            "./results/tokenizer.json\n",
            "./results/spiece.model\n",
            "./results/special_tokens_map.json\n",
            "./results/tokenizer_config.json\n",
            "./results/generation_config.json\n",
            "./results/checkpoint-500/config.json\n",
            "./results/checkpoint-500/model.safetensors\n",
            "./results/checkpoint-500/trainer_state.json\n",
            "./results/checkpoint-500/optimizer.pt\n",
            "./results/checkpoint-500/training_args.bin\n",
            "./results/checkpoint-500/scheduler.pt\n",
            "./results/checkpoint-500/generation_config.json\n",
            "./results/checkpoint-500/rng_state.pth\n",
            "./results/checkpoint-1000/config.json\n",
            "./results/checkpoint-1000/model.safetensors\n",
            "./results/checkpoint-1000/trainer_state.json\n",
            "./results/checkpoint-1000/optimizer.pt\n",
            "./results/checkpoint-1000/training_args.bin\n",
            "./results/checkpoint-1000/scheduler.pt\n",
            "./results/checkpoint-1000/generation_config.json\n",
            "./results/checkpoint-1000/rng_state.pth\n",
            "./results/checkpoint-1500/config.json\n",
            "./results/checkpoint-1500/model.safetensors\n",
            "./results/checkpoint-1500/trainer_state.json\n",
            "./results/checkpoint-1500/optimizer.pt\n",
            "./results/checkpoint-1500/training_args.bin\n",
            "./results/checkpoint-1500/scheduler.pt\n",
            "./results/checkpoint-1500/generation_config.json\n",
            "./results/checkpoint-1500/rng_state.pth\n",
            "./results/runs/Jun08_18-31-55_834c0497bd01/events.out.tfevents.1717872458.834c0497bd01.1116.1\n",
            "./results/runs/Jun08_18-31-55_834c0497bd01/events.out.tfevents.1717871517.834c0497bd01.1116.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j6INSpSSr1gX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip the results directory, including only direct files\n",
        "shutil.make_archive('model', 'zip', './results', './')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tGidJRDgsNQw",
        "outputId": "45fa51cb-99fa-456f-8000-8e9237415d20"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the zipped model to Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja2GZe2JsPK3",
        "outputId": "92d0aedd-f23f-49dc-de5f-0cdd796ff1d5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Copy the zipped model to Google Drive with appropriate naming\n",
        "def copy_to_drive_with_naming(base_name, drive_path):\n",
        "    file_index = 0\n",
        "    while True:\n",
        "        file_name = f\"{base_name}{file_index}.zip\"\n",
        "        destination_path = os.path.join(drive_path, file_name)\n",
        "        if not os.path.exists(destination_path):\n",
        "            shutil.copyfile('model.zip', destination_path)\n",
        "            print(f\"Model saved as: {file_name}\")\n",
        "            break\n",
        "        file_index += 1\n",
        "\n",
        "# Extract the base model name and dataset short name to use as part of the base name\n",
        "base_name = f\"model_{base_model}_{dataset_short_name}_\"\n",
        "copy_to_drive_path = \"/content/drive/My Drive/Models_ML2\"\n",
        "copy_to_drive_with_naming(base_name, copy_to_drive_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtKXnj1K1NEI",
        "outputId": "3aa84a9c-cd67-4238-fb59-4c6155572b06"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as: model_pegasus-large_ECTSum_2.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modell Validierung"
      ],
      "metadata": {
        "id": "EqaVub4UICix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13IT_tIK1Y_b",
        "outputId": "02349a7e-0c84-4f97-cee6-5272561b8476"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from datasets import Dataset, load_metric\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the JSON files\n",
        "train_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_train.jsonl'\n",
        "val_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_val.jsonl'\n",
        "test_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_test.jsonl'\n",
        "\n",
        "# Read the JSONL files\n",
        "train_data = []\n",
        "with open(train_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        train_data.append(json.loads(line))\n",
        "\n",
        "val_data = []\n",
        "with open(val_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        val_data.append(json.loads(line))\n",
        "\n",
        "test_data = []\n",
        "with open(test_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        test_data.append(json.loads(line))\n",
        "\n",
        "# Convert to DataFrames for better handling\n",
        "train_df = pd.DataFrame(train_data)\n",
        "val_df = pd.DataFrame(val_data)\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "# Sample 5% of the data\n",
        "train_df = train_df.sample(frac=0.05, random_state=42)\n",
        "val_df = val_df.sample(frac=0.05, random_state=42)\n",
        "test_df = test_df.sample(frac=0.05, random_state=42)\n",
        "\n",
        "# Convert DataFrames to Datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "validation_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Combine the datasets for preprocessing and fine-tuning\n",
        "combined_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "# Retrieve a random sample\n",
        "random_index = random.randint(0, len(combined_df) - 1)\n",
        "initial_sample = combined_df.iloc[random_index]\n",
        "print(\"Random sample from the initial dataset (before processing):\")\n",
        "print(initial_sample)\n",
        "\n",
        "# Convert DataFrame to Dataset\n",
        "dataset = Dataset.from_pandas(combined_df)\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"google/pegasus-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Define a preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    inputs = [doc for doc in examples[\"input\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Apply the preprocessing function to the dataset\n",
        "processed_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Retrieve the processed sample\n",
        "processed_sample = processed_dataset[random_index]\n",
        "print(\"\\nRandom sample from the processed dataset (after processing):\")\n",
        "print(processed_sample)\n",
        "\n",
        "# Generate summaries for the validation set\n",
        "def generate_summary(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=128, min_length=30, num_beams=5, length_penalty=2.0, early_stopping=True)\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Evaluate the model\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "def evaluate_model(dataset):\n",
        "    summaries = []\n",
        "    references = []\n",
        "    for example in dataset:\n",
        "        summaries.append(generate_summary(example['input']))\n",
        "        references.append(example['summary'])\n",
        "    results = rouge.compute(predictions=summaries, references=references)\n",
        "    return results\n",
        "\n",
        "# Calculate ROUGE scores for the validation set\n",
        "validation_results = evaluate_model(validation_dataset)\n",
        "print(validation_results)\n",
        "\n",
        "# Prepare data for Doc2Vec\n",
        "documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(combined_df['input'])]\n",
        "\n",
        "# Train Doc2Vec model\n",
        "doc2vec_model = Doc2Vec(documents, vector_size=50, window=2, min_count=1, workers=4)\n",
        "\n",
        "# Generate embeddings\n",
        "def get_embedding(text):\n",
        "    return doc2vec_model.infer_vector(text.split())\n",
        "\n",
        "# Calculate cosine similarity\n",
        "def calculate_cosine_similarity(original, summary):\n",
        "    original_embedding = get_embedding(original)\n",
        "    summary_embedding = get_embedding(summary)\n",
        "    return cosine_similarity([original_embedding], [summary_embedding])[0][0]\n",
        "\n",
        "# Example usage\n",
        "example_text = combined_df.iloc[0]['input']\n",
        "example_summary = generate_summary(example_text)\n",
        "cosine_sim = calculate_cosine_similarity(example_text, example_summary)\n",
        "print(f\"Cosine Similarity: {cosine_sim}\")\n",
        "\n",
        "# Copy the zipped model to Google Drive with appropriate naming\n",
        "def copy_to_drive_with_naming(base_name, drive_path):\n",
        "    file_index = 0\n",
        "    while True:\n",
        "        file_name = f\"{base_name}{file_index}.zip\"\n",
        "        destination_path = os.path.join(drive_path, file_name)\n",
        "        if not os.path.exists(destination_path):\n",
        "            shutil.copyfile('model.zip', destination_path)\n",
        "            print(f\"Model saved as: {file_name}\")\n",
        "            break\n",
        "        file_index += 1\n",
        "\n",
        "# Extract the base model name and dataset short name to use as part of the base name\n",
        "base_model = model_name.split('/')[-1]  # Extract 'pegasus-large' from 'google/pegasus-large'\n",
        "dataset_short_name = \"ECTSum\"  # Shortened name for your dataset\n",
        "base_name = f\"model_{base_model}_{dataset_short_name}_\"\n",
        "copy_to_drive_path = \"/content/drive/My Drive/Models_ML2\"\n",
        "copy_to_drive_with_naming(base_name, copy_to_drive_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399,
          "referenced_widgets": [
            "7825c0c66d82438280dbcd7d3299ef8a",
            "fd3bc6fb59134e2ebc4eec17add8ed95",
            "4fe6be5b220d41d490bca62087652895",
            "51ecd5c57db74795a0f431dfd97ba9d2",
            "32ef0cc106014bc3b332841c7a8fd6d3",
            "fc3a18cbc1c54fa59c3251ba021a8225",
            "627b580d42144dbc82fb0fe006cce69d",
            "367ebdffdf1043c5a53ad40adb2a2da3",
            "c32cd45f338345189b641effe097a526",
            "46a8d06a05aa485a94c9ac3eafc5188c",
            "009330a52b8a427c93c1ecb5fbcaf42e"
          ]
        },
        "id": "k_vmGZ0MU3vm",
        "outputId": "4384ab04-cbff-4ffd-aca0-08e57b3c1451"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sample from the initial dataset (before processing):\n",
            "ticker                                                   RYN\n",
            "quarter                                                   q2\n",
            "year                                                    2021\n",
            "input      They are also referenced on Page 2 of our fina...\n",
            "summary    q2 pro forma earnings per share $0.22.\\nq2 ear...\n",
            "Name: 94, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/121 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7825c0c66d82438280dbcd7d3299ef8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random sample from the processed dataset (after processing):\n",
            "{'ticker': 'RYN', 'quarter': 'q2', 'year': '2021', 'input': \"They are also referenced on Page 2 of our financial supplement.\\nWith that, let's start our teleconference with opening comments from Dave Nunes, President and CEO.\\nFirst, I'll make some high-level comments before turning it back over to Mark McHugh, Senior Vice President and Chief Financial Officer to review our consolidated financial results.\\nThen I'll ask Doug Long, our Senior Vice President of Forest Resources, to comment on our U.S. and New Zealand timber results.\\nAnd following the review of our timber segments, Mark will discuss our real estate results as well as our outlook for the balance of 2021.\\nWe are pleased to report that the encouraging momentum we experienced across all our businesses to start 2021 continued into the second quarter.\\nSpecifically, we generated adjusted EBITDA of $95 million and pro forma earnings per share of $0.22 per share.\\nAdjusted EBITDA exceeded the prior-year quarter by 21%, as favorable results in each of our timber segments more than offset lower adjusted EBITDA in the real estate segment.\\nAs we reflect on the second quarter, the operating environment was markedly improved as compared to the prior year period.\\nWe're pleased with how our team continues to capitalize on strong domestic lumber markets improving, real estate market trends and export market opportunities.\\nAs Mark will discuss in greater detail based on our solid first half results and our expectations for the balance of the year, we are modestly raising our 2021 adjusted EBITDA guidance.\\nDrilling down to our different operating segments, our Southern Timber segment generated adjusted EBITDA of $31 million for the quarter, which was 16% above the prior year second quarter.\\nNet stumpage prices increased 14% which more than offset a 4% reduction in harvest volumes as weather conditions impacted productions across the South.\\nIn our Pacific Northwest Timber segment, we achieved adjusted EBITDA of $14 million, an improvement of $10 million versus the prior year quarter.\\nThis sharp increase in adjusted EBITDA was driven by a 30% increase in delivered saw timber prices stemming from favorable domestic lumber markets and increased log export demand as well as higher volumes following the merger with Pope Resources.\\nIn our New Zealand Timber segment.\\nSecond quarter adjusted EBITDA nearly triple to $28 million.\\nThe year-over-year increase in adjusted EBITDA was due to both significantly higher harvest volumes as the second quarter of 2020 was severely impacted by COVID 19 related headwinds and weighted average log prices and increased 51% as a result of robust export and domestic log demand.\\nIn our Real Estate segment, we generated adjusted EBITDA of $29 million, down from $45 million in an exceptionally strong period last year.\\nThe decline versus the prior year quarter was driven by a 61% reduction in acres sold, partially offset by significantly higher per acre prices.\\nImportantly, our real estate team closed significant transactions in both our Wildlight and Belfast Commerce Park development projects during the quarter.\\nSwitching gears from second quarter results, I'd like to provide an update on the Timber Fund business that we acquired last year through our merger with Pope Resources.\\nTwo weeks ago we announced that we had sold the rights to manage to -- of the Timber Funds, as well as our co-investment stake in both of these funds.\\nThe aggregate purchase price was $35.9 million and the transaction will be reflected in our third quarter financial results.\\nAs we had previously communicated the private equity timber funds business was not a long-term strategic fit for Rayonier.\\nWe believe this transaction reflects a favorable outcome for our shareholders.\\nAs it allows us to simplify our operations and allocate capital to other strategic priorities.\\nFollowing this transaction, we continue to manage, as well as own 20% co-investment stake in one Timber Fund comprising 31,000 acres in the Pacific Northwest.\\nSince this fund is at the end of its investment term it was not included in the sale transaction rather we have commenced a process to liquidate the assets from this fund, which if successful will complete our exit from the fund business.\\nLet's start on Page 5 with our financial highlights.\\nSales for the quarter totaled $291 million, while operating income was $84 million and net income attributable to Rayonier was $57 million or $0.41 per share.\\nOn a pro forma basis, net income was $31 million or $0.22 per share.\\nPro forma adjustments for the quarter were primarily associated with a large disposition in the Pacific Northwest, as well as a series of debt actions that I will discuss momentarily.\\nAs Dave touched on second quarter adjusted EBITDA of $95 million was above the prior year period as higher results across all of our timber segments more than offset a lower contribution from our Real Estate segment.\\nOn the bottom of Page 5, we provide an overview of our capital resources and liquidity at quarter-end as well as a comparison to year-end, our cash available for distribution or CAD for the first half of the year was $111 million versus $80 million in the prior-year period, primarily due to higher adjusted EBITDA, partially offset by higher cash taxes, interest expense and capital expenditures.\\nA reconciliation of CAD to cash provided by operating activities and other GAAP measures is provided on Page 8 of the financial supplement.\\nConsistent with our nimble approach to capital allocation, we raised $81 million through our at-the-market equity offering program during the second quarter an average price of $36.79 per share.\\nAs previously discussed, we view the ATM program as a cost-effective tool to opportunistically raise capital strengthen our balance sheet and match fund bolt-on acquisitions.\\nWe are also active in the debt market during the quarter taking steps to address our 2022 bond maturity, improve our debt maturity profile and lower our weighted average borrowing cost.\\nSpecifically in May, we issued $450 million or 2.75% senior notes due 2031.\\nAdditionally while currently remains undrawn.\\nWe executed a credit agreement for a delayed-draw term loan for up to $200 million, which if utilized would mature in 2029.\\nWe also obtained an amendment to lower the interest rate on the term loan we have maturing in 2026 and amended the terms of the debt we assumed in the Pope acquisition to make this debt, unsecured.\\nFurthermore, we also lowered the pricing of our revolving credit facility as well as extended its maturity by year to April 2026.\\nA portion of the proceeds from the May debt offering were used to completely repay a $250 million term loan that was due in 2025.\\nAdditionally, given our strong cash position, following the large disposition completed during the quarter we prepaid $100 million of the term loan that matures in 2026 reducing the outstanding balance to $200 million.\\nIn conjunction with these actions, we recorded a $2.2 million loss associated with the termination of an interest rate swap as well as cost of $1.1 million related to debt extinguishments and modifications.\\nCollectively, these items translated the $0.02 per share, a pro forma adjustments in the quarter.\\nLooking ahead, we believe the actions taken during the quarter help to facilitate an optimal capital structure and leave us with ample liquidity to fund the repayment of our 2022 bond maturity early next year.\\nPro forma for the repayment of our 2022 bond maturity, we expect that our weighted average cost of debt will drop below 3% and our weighted average maturity will extend to roughly seven years.\\nMoreover, almost all of our term debt has been swapped to fixed, which gives us strong visibility on our forecasted interest expense.\\nLastly, by tapping into the bond markets at an advantageous time we preserved additional debt capacity within the farm credit system providing us with increased future financing flexibility.\\nIn sum, we closed the quarter with $310 million of cash and $1.4 billion of debt, both of which exclude cash and debt attributable to the Timber Funds segment which is non-recourse to Rayonier.\\nOur net debt of $1.1 billion represented 17% of our enterprise value based on our closing stock price at the end of the second quarter.\\nLet's start on Page 9 with our Southern Timber segment.\\nAdjusted EBITDA in the second quarter of $31 million was $4 million above the prior year quarter.\\nThe year-over-year improvement was largely attributable to higher net stumpage pricing albeit partially offset by lower harvest volumes.\\nThe 4% decline in volume during the second quarter was largely due to wet weather resulting in lost production days.\\nThis modest decline in volume though was more than offset by higher prices.\\nSpecifically, average sawlog stumpage pricing was roughly $28 per ton, a 10% increase compared to the prior year quarter.\\nImproved pricing strong demand from sawmills as well as improved export log demand in certain markets.\\nPulpwood pricing climbed 14% from the prior year quarter, reflecting robust customer demand, coupled with tighter supply due to wet weather conditions.\\nA favorable mix shift toward our Coastal Atlantic markets also contributed to the strong year-over-year comparison.\\nOverall weighted average pine stumpage prices increased 14% versus the prior year quarter due to higher sawtimber and pulpwood prices as well as a more favorable mix of sawtimber.\\nWe are encouraged by the pricing gains registered during the quarter.\\nWhich underscore the importance of local timber market dynamics across the USL and the construction of our portfolio across those markets.\\nMoving to our Pacific Northwest Timber segment on Page 10.\\nAdjusted EBITDA of $14 million was $10 million above the prior year quarter.\\nThe year-over-year increase was largely attributable to significantly improved pricing due to strong domestic lumber markets and the incremental pension created by healthcare export demand.\\nSecond quarter harvest volume was 4% above the prior year quarter due to additional volume from last year's merger with Pope Resources.\\nAt $98 per ton, our average delivered sawlog price during the second quarter was up 30% from the prior year quarter.\\nStrong pricing was sustained throughout the quarter.\\nEven as lumber prices preceded from the record levels set in May.\\nIn part due to the pricing support created by stronger export market demand meanwhile pulpwood pricing fell 21% in the second quarter relative to prior year quarter.\\nAs sawmill residuals remain plentiful and that increased lumber production.\\nAs it relates to the export market in Pacific Northwest improved demand we discussed on our last call has continued into recent months.\\nThe constricted flow of European Spruce salvage logs, the ban on Australian log exports to China and an improvement in Japanese demand have all contributed to a favorable environment for log exports from the region.\\nAnd we have seen more inventories in China rise in recent weeks.\\nWe believe these forces continues for healthy demand for log exports Pacific Northwest.\\nWe've continued strong demand for domestic sawmills as well as the attention created by the flow of Pacific Northwest marks in the export market will translate into a relatively stable pricing environment in the second half of the year.\\nWhile we are closely monitoring the correction in lumber prices, we believe the underlying log demand remains healthy.\\nIn particular, demand for green logs remained robust given the supply disruptions caused by wildfires, and other regions.\\nOn that note, I'd also like to offer a few comments regarding the risk wildfires across parts of the Western United States.\\nThus far, none of our properties have been seriously threatened by the fires that have impacted the region in 2021.\\nAs a reminder, none of our fee timber properties were impacted by last year's fires, either on the roughly 10,000 acres of timber fund properties sustained fired image.\\nWhile there continues to be upward pressure on higher cost in the areas that have been directly impacted by fires over the past year, our operations have not been materially impacted from the salvage efforts conducted by others.\\nPage 11 shows results and key operating metrics for our New Zealand Timber segment.\\nAdjusted EBITDA in the second quarter of $28 million was nearly triple the $10 million that we reported in the prior year quarter.\\nThe increase in adjusted EBITDA was driven by a much stronger pricing and then more normalized level of harvest activity versus the prior year period constrained by COVID 19 disruptions.\\nIncreased volumes and pricing were partially offset by reduced carbon credit sales.\\nWe continue to defer credit sales during the quarter as we expect that the value of these credits this poised for further price appreciation.\\nTurning to pricing, average delivered prices for export sawtimber jumped 50% in the second quarter from the prior year period to $148 per tonne, reflecting improved China demand the ban on a strain log exports in China and the reduced flow of European Spruce salvage logs into China.\\nAs we've previously noted, prior to the ban Australia was applying approximately 10% of the total volume imported by China.\\nFurthermore shipments of European Spruce salvage logs in the China may constrained by higher transportation costs and the lack of container availability.\\nThese constraints on the flow of logs into China.\\nWhen coupled with the healthy demand translated an exceptionally strong export pricing in New Zealand.\\nUnderscoring the favorable pricing environment A grade log export prices to China surpassed previous record highs during the second quarter.\\nAs reaching record levels, though there has been a pullback in pricing in recent weeks as demand for Radiata logs has softened in response to higher log inventories in China.\\nShifting to the New Zealand domestic market average delivered sawlog prices increased 27% in the prior year period to $85 per ton.\\nThe increase in US dollar pricing was driven primarily by foreign exchange rates and New Zealand domestic pricing improved by more modest 9% in the second quarter versus the prior year quarter.\\nAverage domestic pulpwood pricing declined 35% as compared to the prior year quarter.\\nIn sum, while we expect lower pricing over the balance of the year, our New Zealand operations continue to generate strong net stumpage realizations.\\nWe believe we are well positioned to continue to capture market share from Australia and Europe and the export market as well as benefit from strong domestic demand.\\nI'll now briefly discuss the results from our Timber Funds segment.\\nHighlight on Page 12 Timber Funds segment generated consolidated EBITDA of $8 million in the second quarter on harvest volume of 185,000 tons.\\nAdjusted EBITDA, which reflects the look through contribution from the Timber Funds was $1 million.\\nAs discussed earlier, we are in the process of extinguish Timber Funds business expect contribution from this segment will be negligible moving forward.\\nLastly, in our Trading segment we reported $400,000 of adjusted EBITDA in the second quarter.\\nAs a reminder, our trading activities typically generate low margins in our primarily designed to provide additional economies of scale for fee timber export business.\\nAs detailed on Page 13, our Real Estate segment delivered strong results in the second quarter, second quarter real estate sales totaled $75 million on roughly 17,000 acres sold, which included a large disposition in Washington consisting of roughly 8500 acres.\\nExcluding this transaction, second quarter sales totaled $39 million on roughly 8,000 acres sold at an average price of $4900 per acre.\\nAdjusted EBITDA for the quarter was $29 million.\\nSales in the Improved Development category totaled a record high $19 million in the second quarter as we closed significant transactions within both our Wildlight and Belfast Commerce Park development projects.\\nIn our Wildlight development project north of Jacksonville, Florida sales included a $9.1 million sale of 130 acres to a national homebuilder for the first phase of an active adult community.\\nDue to post closing obligations roughly $5 million of revenue from this transaction was deferred and will be recognized in future periods.\\nThe addition of an active adult community is a significant milestone for the Wildlight project as it adds a complementary market segment, which we believe will help to catalyze additional downstream demand.\\nIn addition, we closed on 36 residential lots in our Wildlight project for $2.3 million or $65 per lot.\\nMeanwhile, in our Belfast Commerce Park development project south of Savannah, Georgia, we sold 153 acre parcel to a national developer of industrial properties for $7.9 million or $51,000 per acre.\\nOverall, we are pleased with the demand for entitled infrastructure served land that is translating into additional momentum across our development projects.\\nWe remain encouraged by the pipeline of opportunities in Wildlight, Richmond Hill and the West Puget Sound area of Washington.\\nIn the rural category sales totaled roughly 7700 acres at an average price of just over $2600 per acre, a nearly 100-acre sale in Georgia to the Conservation Fund comprise the bulk of our second quarter activity.\\nMore broadly, demand for rural land remains healthy as the space privacy and recreational opportunities offered by these properties continue to attract buyers.\\nWe are well positioned to capitalize on these demand trends moving forward and remain focused on achieving price realizations well above timberland values.\\nWe also closed on a conservation easement sale covering 18 acres in Washington for $4 million in the second quarter.\\nThe property covered by this easement was in the Town of Port Gamble, which was acquired as part of the merger with Pope Resources.\\nLastly, if we closed on a large disposition in Western Washington during the quarter for $6 million roughly $100 per acre.\\nThis roughly 8500-acre property was a relatively less strategic holding for us in the region and was sold through a competitive bid process.\\nNow moving on to our outlook for the year.\\nBased on our solid first half results and our expectations for the balance of the year, we are raising our full-year adjusted EBITDA guidance to range of $300 million to $320 million, which reflects a 3% increase at the midpoint from our original guidance.\\nIn our Southern Timber segment, we now expect full year harvest volumes of $5.9 million to $6.1 million tons as production has been constrained by regional weather conditions and trucking availability.\\nWe expect that weighted average pricing will remain above prior year levels, driven by continued strong demand from domestic pulp and lumber mills, as well as improving export demand in select US South markets.\\nHowever, we are seeing higher trucking costs which could limit the upside and net stumpage realizations over the balance of the year, we are taking measures to mitigate the upward pressure on these costs by optimizing whole distances on our deliberate log sales and targeting stumpage sales to customers with great advantages.\\nOverall, we expect full-year adjusted EBITDA of $118 to $122 million and our Southern Timber segment a modest increase from prior guidance.\\nIn our Pacific Northwest Timber segment we are maintaining our full year volume guidance of $1.7 million to $1.8 million tons, along with our full-year adjusted EBITDA guidance of $50 million to $55 million.\\nWe expect pricing in the region, we remain relatively stable as long demand across both the domestic and export markets remains favorable.\\nIn our New Zealand Timber segment, we are maintaining our full year volume guidance of $2.6 million to $2.8 million tons.\\nGiven the robust start to 2021, we now expect full-year adjusted EBITDA of $78 million to $82 million.\\nThat said, we expect relatively lower export pricing over the second half of the year as log inventories in China have increased significantly in recent weeks.\\nFurther, we anticipate that shipping and demurrage costs will remain elevated.\\nIn our Real Estate segment, we now expect full-year adjusted EBITDA of $78 million to $86 million.\\nWe expect a strong second half of the year in this segment given the healthy demand for residential and commercial properties within our real estate development projects, as well as continued strength in rural land sales activity.\\nOverall, we're very pleased with the quarter and optimistic about our outlook for the balance of the year.\\nAs I reflect on the last 18 months.\\nI'm very proud of how our team has successfully navigated pandemic related disruptions and integrated Pope Resources, while also continuing to execute on several other strategic priorities.\\nTo this end, in the second quarter, we continue to improve our portfolio through both addition and subtraction.\\nWe opportunistically recycled capital out of a non-strategic timberland holding in Washington State while also closing on a total of $22 million of bolt-on acquisitions.\\nThese portfolio moves have helped us improve our positioning in the strongest softwood log markets in the US and New Zealand, which should help us grow both cash flows and value per share over time.\\nSubsequent to quarter end, we also closed on the sale of two Timber Funds, an important step toward exiting a private equity fund business that is not a strategic fit for Rayonier.\\nMeanwhile, the benefits of the strategic investments we've made on the real estate front, are being increasingly realized as quarterly improved development real estate sales reached a record high in the second quarter.\\nFurthermore, we took steps to optimize our cost of capital and better position our balance sheet for long-term growth by accessing both the debt and equity markets during the quarter.\\nIn addition to achieving important operational and financial goals, we also continue to embrace the increased interest from stakeholders in our environmental social and governance practices.\\nAs previously discussed, we believe our mission of providing industry-leading returns while serving as a responsible steward of the lands is well aligned with key ESG principles that we're looking to advance.\\nBuilding on the inaugural carbon report we published earlier this year, we are planning to release a comprehensive sustainability report in the coming weeks, which will further enhance our ESG disclosures.\\nOverall I continue to be impressed by the dedication and focus of our employees as they work together to better position Rayonier for long-term success.\\n\", 'summary': 'q2 pro forma earnings per share $0.22.\\nq2 earnings per share $0.41.\\nanticipate full-year net income attributable to rayonier of $98 to $106 million, earnings per share of $0.69 to $0.75.\\nanticipate full-year pro forma earnings per share of $0.51 to $0.57, and adjusted ebitda of $300 to $320 million.\\n', 'input_ids': [322, 127, 163, 15368, 124, 3872, 280, 113, 150, 748, 5701, 107, 441, 120, 108, 538, 131, 116, 388, 150, 69120, 122, 1671, 1770, 135, 5861, 71916, 108, 1276, 111, 2792, 107, 1485, 108, 125, 131, 267, 193, 181, 281, 121, 3393, 1770, 269, 3169, 126, 247, 204, 112, 2538, 85366, 108, 4244, 5376, 1276, 111, 3670, 3650, 4697, 112, 933, 150, 17685, 748, 602, 107, 1249, 125, 131, 267, 854, 11283, 2859, 108, 150, 4244, 5376, 1276, 113, 4453, 5562, 108, 112, 1929, 124, 150, 475, 107, 283, 107, 111, 351, 3571, 7872, 602, 107, 325, 645, 109, 933, 113, 150, 7872, 8662, 108, 2538, 138, 1693, 150, 440, 1432, 602, 130, 210, 130, 150, 8337, 118, 109, 1716, 113, 34315, 184, 127, 3042, 112, 731, 120, 109, 5281, 7659, 145, 1267, 482, 149, 150, 1098, 112, 388, 30013, 2059, 190, 109, 453, 2349, 107, 16736, 108, 145, 3943, 7460, 45260, 113, 45556, 604, 111, 2717, 118, 3225, 5264, 446, 537, 113, 68856, 522, 446, 537, 107, 25832, 316, 45260, 12710, 109, 1620, 121, 1019, 2349, 141, 38444, 108, 130, 11123, 602, 115, 276, 113, 150, 7872, 8662, 154, 197, 8785, 1074, 7460, 45260, 115, 109, 440, 1432, 5125, 107, 398, 145, 3291, 124, 109, 453, 2349, 108, 109, 1901, 849, 140, 39878, 2521, 130, 1711, 112, 109, 1620, 232, 908, 107, 184, 131, 216, 3042, 122, 199, 150, 320, 2138, 112, 22402, 124, 806, 2970, 15857, 2099, 3024, 108, 440, 1432, 407, 2994, 111, 5428, 407, 1170, 107, 398, 2538, 138, 1693, 115, 1626, 2011, 451, 124, 150, 1907, 211, 751, 602, 111, 150, 2772, 118, 109, 1716, 113, 109, 232, 108, 145, 127, 53193, 4673, 150, 30013, 7460, 45260, 3090, 107, 37570, 308, 112, 150, 291, 1901, 8662, 108, 150, 3515, 18475, 5125, 3943, 7460, 45260, 113, 44439, 604, 118, 109, 2349, 108, 162, 140, 30316, 607, 109, 1620, 232, 453, 2349, 107, 6007, 24951, 3528, 1068, 1562, 29230, 162, 154, 197, 8785, 114, 18700, 3746, 115, 7924, 7912, 130, 1403, 1047, 9532, 14533, 482, 109, 793, 107, 222, 150, 3755, 9170, 18475, 5125, 108, 145, 3310, 7460, 45260, 113, 18595, 604, 108, 142, 2757, 113, 5298, 604, 6075, 109, 1620, 232, 2349, 107, 182, 4565, 815, 115, 7460, 45260, 140, 3830, 141, 114, 7732, 815, 115, 2336, 1148, 7872, 1068, 32885, 135, 11123, 2970, 15857, 2099, 111, 1562, 3283, 5428, 1806, 130, 210, 130, 902, 7912, 645, 109, 12780, 122, 11481, 5562, 107, 222, 150, 351, 3571, 18475, 5125, 107, 4317, 2349, 7460, 45260, 1517, 7459, 112, 30376, 604, 107, 139, 232, 121, 4016, 121, 1019, 815, 115, 7460, 45260, 140, 640, 112, 302, 2838, 902, 7924, 7912, 130, 109, 453, 2349, 113, 7149, 140, 11526, 9532, 141, 4585, 44078, 1925, 985, 71915, 111, 20420, 1077, 3283, 1068, 111, 1562, 39726, 130, 114, 711, 113, 5076, 5428, 111, 2970, 3283, 1806, 107, 222, 150, 2817, 4411, 5125, 108, 145, 3943, 7460, 45260, 113, 27785, 604, 108, 308, 135, 21645, 604, 115, 142, 10499, 806, 908, 289, 232, 107, 139, 5088, 6075, 109, 1620, 232, 2349, 140, 3830, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [15593, 522, 2717, 118, 3225, 5264, 446, 537, 68856, 1979, 15593, 522, 5264, 446, 537, 72323, 2192, 9299, 357, 121, 1019, 2677, 1643, 32414, 112, 44759, 4063, 113, 81510, 112, 5298, 1717, 604, 108, 5264, 446, 537, 113, 83521, 2507, 112, 75938, 3311, 9299, 357, 121, 1019, 2717, 118, 3225, 5264, 446, 537, 113, 72117, 740, 112, 72117, 18903, 111, 7460, 860, 5071, 3347, 113, 14175, 112, 7152, 3214, 604, 107, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': AggregateScore(low=Score(precision=0.10069542522141246, recall=0.20626689576105772, fmeasure=0.13011459345259102), mid=Score(precision=0.15735082643832396, recall=0.27128224792524913, fmeasure=0.18269335043161355), high=Score(precision=0.22288121689797957, recall=0.34846039609415697, fmeasure=0.24301559253617208)), 'rouge2': AggregateScore(low=Score(precision=0.01700599515501766, recall=0.03327044284619749, fmeasure=0.021160726890271826), mid=Score(precision=0.03642339764013851, recall=0.0655121620582147, fmeasure=0.04248577369142957), high=Score(precision=0.058641066954941166, recall=0.10484322373568697, fmeasure=0.06793965972585275)), 'rougeL': AggregateScore(low=Score(precision=0.06613850627618058, recall=0.13387285242268207, fmeasure=0.08497499123344793), mid=Score(precision=0.09405162949308171, recall=0.17367011362615983, fmeasure=0.11168953272097094), high=Score(precision=0.1291017198637173, recall=0.21934301267355805, fmeasure=0.14641965722184475)), 'rougeLsum': AggregateScore(low=Score(precision=0.08068865954025274, recall=0.166431879478999, fmeasure=0.10308557493833106), mid=Score(precision=0.12654131177015307, recall=0.21842083631217202, fmeasure=0.14669503950416002), high=Score(precision=0.18331192253114828, recall=0.28318152798942337, fmeasure=0.1995113245453334))}\n",
            "Cosine Similarity: 0.8318020105361938\n",
            "Model saved as: model_pegasus-large_ECTSum_3.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation of full set"
      ],
      "metadata": {
        "id": "VxIQJPf2VHuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from datasets import Dataset, load_metric\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the JSON files\n",
        "train_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_train.jsonl'\n",
        "val_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_val.jsonl'\n",
        "test_json_file_path = '/content/drive/My Drive/Data_ML2/ECTSum_test.jsonl'\n",
        "\n",
        "# Read the JSONL files\n",
        "train_data = []\n",
        "with open(train_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        train_data.append(json.loads(line))\n",
        "\n",
        "val_data = []\n",
        "with open(val_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        val_data.append(json.loads(line))\n",
        "\n",
        "test_data = []\n",
        "with open(test_json_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        test_data.append(json.loads(line))\n",
        "\n",
        "# Convert to DataFrames for better handling\n",
        "train_df = pd.DataFrame(train_data)\n",
        "val_df = pd.DataFrame(val_data)\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "# Convert DataFrames to Datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "validation_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Combine the datasets for preprocessing and fine-tuning\n",
        "combined_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "# Retrieve a random sample\n",
        "random_index = random.randint(0, len(combined_df) - 1)\n",
        "initial_sample = combined_df.iloc[random_index]\n",
        "print(\"Random sample from the initial dataset (before processing):\")\n",
        "print(initial_sample)\n",
        "\n",
        "# Convert DataFrame to Dataset\n",
        "dataset = Dataset.from_pandas(combined_df)\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"google/pegasus-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Define a preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    inputs = [doc for doc in examples[\"input\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Apply the preprocessing function to the dataset\n",
        "processed_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Retrieve the processed sample\n",
        "processed_sample = processed_dataset[random_index]\n",
        "print(\"\\nRandom sample from the processed dataset (after processing):\")\n",
        "print(processed_sample)\n",
        "\n",
        "# Generate summaries for the validation set\n",
        "def generate_summary(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=128, min_length=30, num_beams=5, length_penalty=2.0, early_stopping=True)\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Evaluate the model\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "def evaluate_model(dataset):\n",
        "    summaries = []\n",
        "    references = []\n",
        "    for example in dataset:\n",
        "        summaries.append(generate_summary(example['input']))\n",
        "        references.append(example['summary'])\n",
        "    results = rouge.compute(predictions=summaries, references=references)\n",
        "    return results\n",
        "\n",
        "# Calculate ROUGE scores for the validation set\n",
        "validation_results = evaluate_model(validation_dataset)\n",
        "print(validation_results)\n",
        "\n",
        "# Prepare data for Doc2Vec\n",
        "documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(combined_df['input'])]\n",
        "\n",
        "# Train Doc2Vec model\n",
        "doc2vec_model = Doc2Vec(documents, vector_size=50, window=2, min_count=1, workers=4)\n",
        "\n",
        "# Generate embeddings\n",
        "def get_embedding(text):\n",
        "    return doc2vec_model.infer_vector(text.split())\n",
        "\n",
        "# Calculate cosine similarity\n",
        "def calculate_cosine_similarity(original, summary):\n",
        "    original_embedding = get_embedding(original)\n",
        "    summary_embedding = get_embedding(summary)\n",
        "    return cosine_similarity([original_embedding], [summary_embedding])[0][0]\n",
        "\n",
        "# Example usage\n",
        "example_text = combined_df.iloc[0]['input']\n",
        "example_summary = generate_summary(example_text)\n",
        "cosine_sim = calculate_cosine_similarity(example_text, example_summary)\n",
        "print(f\"Cosine Similarity: {cosine_sim}\")\n",
        "\n",
        "# Copy the zipped model to Google Drive with appropriate naming\n",
        "def copy_to_drive_with_naming(base_name, drive_path):\n",
        "    file_index = 0\n",
        "    while True:\n",
        "        file_name = f\"{base_name}{file_index}.zip\"\n",
        "        destination_path = os.path.join(drive_path, file_name)\n",
        "        if not os.path.exists(destination_path):\n",
        "            shutil.copyfile('model.zip', destination_path)\n",
        "            print(f\"Model saved as: {file_name}\")\n",
        "            break\n",
        "        file_index += 1\n",
        "\n",
        "# Extract the base model name and dataset short name to use as part of the base name\n",
        "base_model = model_name.split('/')[-1]  # Extract 'pegasus-large' from 'google/pegasus-large'\n",
        "dataset_short_name = \"ECTSum\"  # Shortened name for your dataset\n",
        "base_name = f\"model_{base_model}_{dataset_short_name}_\"\n",
        "copy_to_drive_path = \"/content/drive/My Drive/Models_ML2\"\n",
        "copy_to_drive_with_naming(base_name, copy_to_drive_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770,
          "referenced_widgets": [
            "5053345ca1ce4f249f204187edd6c3c6",
            "b11f01b8af9d4f81b72c0fe48f873677",
            "2b353e37c6f8473ca7f15eddab73dbb0",
            "8dffbf5167dc447baa48bec3493486a1",
            "af078c18a50e4b72a1c03438a0960279",
            "94b04377d1074b9d8b805095ee9e2210",
            "81091e63d1514fae96781d0268740bac",
            "1ab2ac81fd2a478ba2f3a657473a469c",
            "8d5291091ba94c319a536e194805d057",
            "9373cdc0dcbb411c971c5f4d56c45208",
            "279d8217bc6d4b97bf45791645ffd54c",
            "eec8f999763d4bd19f4c185c4a2c2622",
            "bb230a3c68054baf804c15207ffd3a6d",
            "9cf9c125a156471f9ad5f08754bea1ba",
            "a7b33dfa05254932b71c76b2a9ff16f1",
            "bac2ea678c1b4357b4d718750a22f4ab",
            "bd885dff3de8498081e9b3cc5efb202d",
            "afb318cbf3aa481db17db8d03fb87d30",
            "5bb7cf12b1d849198350447953a4a19a",
            "521f2798319e49559a1a8d786efda1f5",
            "8a479f60f3c447e4b34628676ab300b1",
            "ed3bc433f2bb442abc6cff9227382342"
          ]
        },
        "id": "dP1IA0UqTXcE",
        "outputId": "2d92c6c9-d43d-4ad3-f229-b8abc7c59f84"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sample from the initial dataset (before processing):\n",
            "ticker                                                   ARI\n",
            "quarter                                                   q4\n",
            "year                                                    2020\n",
            "input      We hope that everyone listening continues to b...\n",
            "summary    compname reports q4 earnings per share $0.23.\\...\n",
            "Name: 102, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2425 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5053345ca1ce4f249f204187edd6c3c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random sample from the processed dataset (after processing):\n",
            "{'ticker': 'ARI', 'quarter': 'q4', 'year': '2020', 'input': 'We hope that everyone listening continues to be safe and healthy as we work through the challenges related to the pandemic.\\nIt is impossible to review ARI\\'s 2020 performance or discuss current market conditions and the implications for ARI\\'s future strategic priorities without acknowledging the initial and ongoing impact of the pandemic.\\nUltimately, the real estate market resides at the intersection of the economy and the capital markets.\\nTo frame my comments in the appropriate context, it is important to note that despite initial concerns expressed by those who viewed the pandemic through the lens of the Global Financial Crisis, over the past 11 months the capital markets have remained functioning and experienced an historically rapid recovery.\\nHowever, overall economic performance is recovering slowly, and the ultimate trajectory of the economy will depend on the pace at which fiscal and regulatory policies and capital investment are able to minimize the impact of the pandemic and the ongoing vaccination efforts enable the reopening of as much of the pre-pandemic economy as possible.\\nUnlike every other year-end earnings call in ARI\\'s history when we would typically highlight origination volume, growth in the capital base and portfolio as well as capital efficiency, we believe ARI\\'s performance in 2020 is best measured by the company\\'s balance sheet durability and effective proactive asset management.\\nDuring the year, the in-place strength of the balance sheet was enhanced through effective liquidity management predicated on strong relationships with each of our lenders as well as opportunistic and well-priced asset sales.\\nARI\\'s asset management efforts benefited from our ongoing investment in both talent and systems and our historic practice of keeping originators involved with their transactions, which facilitates dialogue with and information flow from our borrowers.\\nThe tremendous skill set of Apollo\\'s commercial real estate debt team and the resources, thought leadership and relationships that come from being part of the broader Apollo organization were instrumental to ARI\\'s achievements in 2020 and continue to differentiate ARI in the marketplace.\\nImportantly, the net result of our 2020 efforts was ARI\\'s continued ability to pay a well-covered dividend to our shareholders.\\nThe onset of the pandemic immediately led to concerns over liquidity throughout the real estate sector and heightened security of balance sheet strength and bank lending relationships across mortgage REITs.\\nIn managing ARI\\'s balance sheet, we have always focused on implementing a leverage strategy consistent with our asset mix, balancing the use of leverage with return targets, not relying on max leverage on any one asset to generate a target return and maintaining an unencumbered pool of loans.\\nWe have consistently maintained strong relationships with our lenders, always seeking to keep an open and candid dialogue and ensuring that ARI fully benefits from the One Apollo approach to managing relationships with key financial partners.\\nThis approach was validated during 2020, as we materially increased ARI\\'s short-term liquidity without the need for any form of rescue capital or having to access the capital markets from a position of weakness during the peak of capital markets volatility.\\nBeyond ARI\\'s basic financial strategy, we also chose to opportunistically sell loans at attractive pricing, generating excess liquidity and eliminating some of our construction and future funding commitments.\\nDuring 2020, ARI sold approximately $634 million of loans at a weighted-average price of 98.1% of par, generating net proceeds of $208 million.\\nGiven the significant amount of capital searching for yield, the market for loan sales remains active, and when and if appropriate we may consider additional sales on behalf of ARI.\\nAnother highlight of 2020 was ARI\\'s considered use of its share repurchase plan.\\nIn growing ARI, we have maintained our commitment to only issue common stock above book value.\\nIn 2020, we remained thoughtful with respect to how our capital allocation could positively impact book value given the pandemic-driven downward pressure on our common stock price.\\nAs such, we determined repurchasing ARI\\'s common stock would achieve the best risk-adjusted return on equity for our excess capital.\\nAs a result, we repurchased over $128 million of common stock at an average price of $8.61, resulting in approximately $0.61 per share of book value accretion.\\nI also want to highlight that yesterday we announced our board of directors authorized a $150 million increase to ARI\\'s share repurchase plan, providing us with total capacity of $172 million.\\nPivoting to the portfolio, ARI\\'s focus for 2020 was proactive asset management.\\nOur efforts were greatly enhanced through the access to the resources of the Apollo platform, providing our team with extensive real-time data and information.\\nIn prior quarters, we have spoken extensively about the challenges within various property types or specific assets in our portfolio.\\nGiven the underlying LTV of our loans, the ongoing dialogue with our borrowers and the measured recovery in the economy, I am pleased to report that there are no material changes to the credit quality of the portfolio or to our credit outlook since the last call.\\nAnecdotally, with respect to our loans underlying the hospitality assets, we continue to see steady improvement within the roughly 65% of our portfolio which are resort or destination locations, while business-oriented hotels continue to face challenges.\\nWith respect to the Anaheim hotel that was foreclosed upon and is being carried as REO, the hotel is under contract to be sold, and a hard deposit has been posted.\\nLastly, with respect to two of our largest focused loans, we have had positive momentum at both the Miami Design District loan and the Fulton Street loan.\\nWith respect to Miami Design, since the last earnings call we entered into a partnership with an extremely well regarded local developer who is converting the space into an open-air marketplace and working on leasing the existing space, while retaining the option to redevelop the property at a later date.\\nOn Fulton Street, we partnered with a best-in-class New York developer to redevelop the site into a multifamily property.\\nThe one additional loan I want to discuss is our first mortgage secured by an urban retail property in London.\\nThe property is located in one of the most trafficked locations on Oxford Circus in London, and it houses Topchop\\'s and Nike\\'s flagship stores.\\nLast quarter, Topshop\\'s parent company, Arcadia, filed for bankruptcy.\\nThis was an outcome we considered when we underwrote the loan, as we were extremely familiar with the credit.\\nThe property is currently being marketed for sale, and the initial feedback from the process indicates the proceeds will be well in excess of our loan.\\nThe loan is currently accruing interest, including default interest, and we believe we are well covered.\\nAs we look ahead, we believe ARI is well positioned to capitalize on the significant increase in real estate transaction activity which began in the latter part of 2020 and has continued in 2021.\\nThe commercial real estate market is benefiting from the low interest rate environment and record amounts of dry powder in real estate funds, which is leading to increased deal activity.\\nARI entered 2021 with excess capital on its balance sheet and is positioned to deploy that capital into attractive risk-adjusted return opportunities.\\nAlso, given the current strength of the capital markets, we believe ARI will be repaid on some of its existing loans, thereby providing additional capital to be invested.\\nApollo\\'s real estate credit platform remained active throughout 2020 and continues to see a tremendous amount of transaction flow, which has enabled ARI to thoughtfully build a pipeline of potential new deals.\\nImportantly, ARI\\'s lenders have indicated their willingness to provide ARI with financing for new transactions, and we are confident that levered returns achievable today are consistent with the returns on the capital we are expecting back this year.\\nAs always, our focus on capital allocation will remain on generating the most attractive risk-adjusted ROE.\\nWe will remain steadfast to our credit-first methodology, and we will be prudent in our capital management in funding new business.\\nWe recently committed to our first transaction in 2021, a large first mortgage loan in Europe, and the pipeline continues to build.\\nThis was achievable even with excess liquidity on our balance sheet through most of 2020.\\nOur common stock offers investors in excess of an 11-plus percent dividend yield, which we believe is extremely attractive in this current low yield environment.\\nBefore we review earnings, I wanted to discuss our secured financing arrangements.\\nFrom March 15 of last year, total deleveraging on our $3.5 billion financing arrangements were $190 million, which is less than 6% of our outstanding balance.\\nOur strong relationships with key counterparties were beneficial as we navigated volatility in the capital markets throughout the past 11 months.\\nWe also proactively worked with our financing partners and availed ourselves of the benefits of the broader Apollo platform to ensure adequate liquidity and term-out financing.\\nI want to highlight that beginning of this quarter we will use the words \"distributable earnings\" instead of \"operating earnings,\" with no change to the definition.\\nFor the fourth quarter of 2020, our distributable earnings prior to realized loss on investments were $51 million, or $0.36 per share of common stock.\\nDistributable earnings were $21 million, or $0.15 per share, and the realized loss on investments was comprised of $25 million in previously recorded specific CECL reserves and $5 million on loan sales and restructurings.\\nGAAP net income available to common stockholders was $33 million, or $0.23 per share, and the common stock dividend for the quarter was $0.35 per share.\\nAs of December 31, our General CECL Reserve remained relatively unchanged, declining by three basis points to 68 basis points, and our total CECL reserve now stands at 3.24% of our portfolio.\\nMoving to book value.\\nGAAP book value per share prior to the General CECL Reserve was $15.38, as compared to $15.30 at the end of the third quarter.\\nThe increase was primarily due to the accretive share repurchases Stuart mentioned earlier.\\nSince the end of the first quarter of last year, our book value prior to General CECL Reserve increased by $0.44 per share.\\nAt quarter-end, our $6.5 billion loan portfolio had a weighted-average unlevered yield of 6.3% and a remaining fully extended term of just under three years.\\nApproximately 90% of our floating-rate U.S. loans have LIBOR floors that are in the money today, with a weighted-average floor of 1.46%.\\nWe completed $109 million of add-on fundings during the quarter for previously closed loans, bringing our total add-on fundings to $413 million for 2020.\\nAnd lastly, with respect to our borrowings we are in compliance with all covenants and continue to maintain strong liquidity.\\nAs of today, we have $250 million of cash on hand, $30 million of approved undrawn credit capacity and $1.1 billion in unencumbered loan assets.\\n', 'summary': \"compname reports q4 earnings per share $0.23.\\nq4 earnings per share $0.23.\\napollo commercial real estate finance - company's board of directors authorized increase of $150 million to existing share repurchase plan.\\n\", 'input_ids': [184, 715, 120, 688, 3343, 2138, 112, 129, 963, 111, 1200, 130, 145, 201, 224, 109, 1628, 985, 112, 109, 41428, 107, 168, 117, 3394, 112, 933, 110, 53424, 131, 116, 7149, 637, 132, 1693, 582, 407, 1047, 111, 109, 7418, 118, 110, 53424, 131, 116, 533, 3112, 7001, 347, 21832, 109, 2061, 111, 3121, 979, 113, 109, 41428, 107, 15824, 108, 109, 440, 1432, 407, 14807, 134, 109, 9629, 113, 109, 1968, 111, 109, 1863, 2099, 107, 413, 2005, 161, 1770, 115, 109, 1530, 2956, 108, 126, 117, 356, 112, 1351, 120, 2409, 2061, 2084, 4470, 141, 274, 170, 3336, 109, 41428, 224, 109, 4022, 113, 109, 2871, 3650, 19614, 108, 204, 109, 555, 1073, 590, 109, 1863, 2099, 133, 4615, 7233, 111, 1267, 142, 11318, 4686, 2597, 107, 611, 108, 1380, 1500, 637, 117, 11930, 3642, 108, 111, 109, 3233, 19486, 113, 109, 1968, 138, 4655, 124, 109, 3644, 134, 162, 7037, 111, 5049, 2154, 111, 1863, 1237, 127, 350, 112, 6976, 109, 979, 113, 109, 41428, 111, 109, 3121, 19138, 1645, 2392, 109, 44562, 113, 130, 249, 113, 109, 1133, 121, 1379, 526, 30678, 1968, 130, 433, 107, 6857, 290, 176, 232, 121, 2797, 5264, 443, 115, 110, 53424, 131, 116, 689, 173, 145, 192, 2222, 4135, 45432, 2410, 108, 874, 115, 109, 1863, 1217, 111, 3376, 130, 210, 130, 1863, 2542, 108, 145, 697, 110, 53424, 131, 116, 637, 115, 7149, 117, 229, 5844, 141, 109, 301, 131, 116, 1716, 2614, 6832, 111, 957, 10774, 4058, 603, 107, 2348, 109, 232, 108, 109, 115, 121, 10016, 1881, 113, 109, 1716, 2614, 140, 4934, 224, 957, 18325, 603, 57614, 124, 806, 2074, 122, 276, 113, 150, 7629, 130, 210, 130, 49033, 111, 210, 121, 19884, 4058, 835, 107, 110, 53424, 131, 116, 4058, 603, 1645, 16761, 135, 150, 3121, 1237, 115, 302, 2923, 111, 747, 111, 150, 3246, 846, 113, 1727, 48080, 116, 1065, 122, 153, 4144, 108, 162, 16155, 5762, 122, 111, 257, 1971, 135, 150, 16623, 107, 139, 6550, 3016, 323, 113, 16198, 131, 116, 1162, 440, 1432, 2271, 320, 111, 109, 1040, 108, 666, 2071, 111, 2074, 120, 331, 135, 270, 297, 113, 109, 7792, 16198, 1134, 195, 9053, 112, 110, 53424, 131, 116, 7196, 115, 7149, 111, 801, 112, 15343, 110, 53424, 115, 109, 6076, 107, 48614, 108, 109, 2677, 711, 113, 150, 7149, 1645, 140, 110, 53424, 131, 116, 2059, 986, 112, 626, 114, 210, 121, 20624, 13138, 112, 150, 9843, 107, 139, 16121, 113, 109, 41428, 1501, 1358, 112, 2084, 204, 18325, 720, 109, 440, 1432, 1827, 111, 19974, 750, 113, 1716, 2614, 1881, 111, 1679, 8551, 2074, 482, 3363, 63914, 107, 222, 3136, 110, 53424, 131, 116, 1716, 2614, 108, 145, 133, 329, 1957, 124, 5745, 114, 7043, 1520, 3302, 122, 150, 4058, 1707, 108, 11297, 109, 207, 113, 7043, 122, 935, 5128, 108, 146, 11763, 124, 8195, 7043, 124, 189, 156, 4058, 112, 3210, 114, 1762, 935, 111, 3690, 142, 84269, 1536, 113, 2780, 107, 184, 133, 4409, 4099, 806, 2074, 122, 150, 7629, 108, 329, 2486, 112, 376, 142, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [12009, 7982, 1574, 15593, 914, 5264, 446, 537, 68856, 2204, 15593, 914, 5264, 446, 537, 68856, 2204, 114, 32952, 554, 1162, 440, 1432, 3324, 233, 301, 131, 116, 1042, 113, 5976, 6392, 815, 113, 15777, 604, 112, 1385, 537, 45194, 511, 107, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-14ff11773fae>:82: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge = load_metric(\"rouge\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eec8f999763d4bd19f4c185c4a2c2622"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-14ff11773fae>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m# Calculate ROUGE scores for the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mvalidation_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-14ff11773fae>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msummaries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mreferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-14ff11773fae>\u001b[0m in \u001b[0;36mgenerate_summary\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0msummary_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   1796\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2709\u001b[0m                 \u001b[0mnext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m                 next_token_scores, next_tokens = torch.topk(\n\u001b[0m\u001b[1;32m   2712\u001b[0m                     \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tokens_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}